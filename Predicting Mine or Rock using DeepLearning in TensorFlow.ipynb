{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df=pd.read_csv('sonar.csv')\n",
    "    X=df[df.columns[0:60]].values\n",
    "    y=df[df.columns[60]]\n",
    "    \n",
    "    #Encode the dependent variable\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y=encoder.transform(y)\n",
    "    Y=one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the encoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels=len(labels)\n",
    "    n_unique_labels=len(np.unique(labels))\n",
    "    one_hot_encode=np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels]=1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n"
     ]
    }
   ],
   "source": [
    "X,Y=read_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the data set and mix up the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=shuffle(X,Y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.20,random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the shape of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165, 2)\n",
      "(42, 60)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the important parameters and variables to work with the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 60\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.3\n",
    "training_epochs=1000\n",
    "cost_history=[]\n",
    "n_dim=X.shape[1]\n",
    "print(\"n_dim\",n_dim)\n",
    "n_class=2\n",
    "model_path=\"C:\\\\Users\\\\ayana\\\\Documents\\\\ML\\\\Machine Learning With Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1=60\n",
    "n_hidden_2=60\n",
    "n_hidden_3=60\n",
    "n_hidden_4=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,n_dim])\n",
    "W=tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b=tf.Variable(tf.zeros([n_class]))\n",
    "y_=tf.placeholder(tf.float32,[None,n_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    # Hidden Layer with RELU activation\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    # Hidden layer with sigmoid activation\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    #Output layer with Linear activation\n",
    "    \n",
    "    out_layer=tf.matmul(layer_4,weights['out'])+biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the weights and biases for each layer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1':tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y,labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the cost and accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 0.341936 -MSE: 1.41430972986 -Train Accuracy: 0.848485\n",
      "epoch: 1 - cost: 0.354019 -MSE: 1.35351788209 -Train Accuracy: 0.830303\n",
      "epoch: 2 - cost: 0.340906 -MSE: 1.4150448925 -Train Accuracy: 0.848485\n",
      "epoch: 3 - cost: 0.352882 -MSE: 1.35355734814 -Train Accuracy: 0.830303\n",
      "epoch: 4 - cost: 0.339885 -MSE: 1.41581248522 -Train Accuracy: 0.848485\n",
      "epoch: 5 - cost: 0.351757 -MSE: 1.35364598304 -Train Accuracy: 0.830303\n",
      "epoch: 6 - cost: 0.338874 -MSE: 1.41661212236 -Train Accuracy: 0.848485\n",
      "epoch: 7 - cost: 0.350643 -MSE: 1.3537842766 -Train Accuracy: 0.830303\n",
      "epoch: 8 - cost: 0.337871 -MSE: 1.41744374951 -Train Accuracy: 0.848485\n",
      "epoch: 9 - cost: 0.34954 -MSE: 1.35397033303 -Train Accuracy: 0.830303\n",
      "epoch: 10 - cost: 0.336877 -MSE: 1.41830699028 -Train Accuracy: 0.848485\n",
      "epoch: 11 - cost: 0.348448 -MSE: 1.35420444498 -Train Accuracy: 0.830303\n",
      "epoch: 12 - cost: 0.335892 -MSE: 1.41920171399 -Train Accuracy: 0.848485\n",
      "epoch: 13 - cost: 0.347366 -MSE: 1.35448530546 -Train Accuracy: 0.830303\n",
      "epoch: 14 - cost: 0.334916 -MSE: 1.42012778544 -Train Accuracy: 0.842424\n",
      "epoch: 15 - cost: 0.346295 -MSE: 1.35481271969 -Train Accuracy: 0.830303\n",
      "epoch: 16 - cost: 0.333948 -MSE: 1.42108468883 -Train Accuracy: 0.842424\n",
      "epoch: 17 - cost: 0.345234 -MSE: 1.35518586204 -Train Accuracy: 0.830303\n",
      "epoch: 18 - cost: 0.332988 -MSE: 1.42207259372 -Train Accuracy: 0.842424\n",
      "epoch: 19 - cost: 0.344183 -MSE: 1.35560433912 -Train Accuracy: 0.830303\n",
      "epoch: 20 - cost: 0.332037 -MSE: 1.42309095342 -Train Accuracy: 0.842424\n",
      "epoch: 21 - cost: 0.343142 -MSE: 1.35606670566 -Train Accuracy: 0.830303\n",
      "epoch: 22 - cost: 0.331093 -MSE: 1.42413873225 -Train Accuracy: 0.842424\n",
      "epoch: 23 - cost: 0.342111 -MSE: 1.35657278821 -Train Accuracy: 0.830303\n",
      "epoch: 24 - cost: 0.330158 -MSE: 1.42521646122 -Train Accuracy: 0.842424\n",
      "epoch: 25 - cost: 0.341089 -MSE: 1.35712180093 -Train Accuracy: 0.836364\n",
      "epoch: 26 - cost: 0.329231 -MSE: 1.42632344665 -Train Accuracy: 0.848485\n",
      "epoch: 27 - cost: 0.340077 -MSE: 1.35771360371 -Train Accuracy: 0.836364\n",
      "epoch: 28 - cost: 0.328311 -MSE: 1.42745968335 -Train Accuracy: 0.848485\n",
      "epoch: 29 - cost: 0.339074 -MSE: 1.35834601662 -Train Accuracy: 0.836364\n",
      "epoch: 30 - cost: 0.327399 -MSE: 1.42862428468 -Train Accuracy: 0.848485\n",
      "epoch: 31 - cost: 0.33808 -MSE: 1.35901979977 -Train Accuracy: 0.836364\n",
      "epoch: 32 - cost: 0.326494 -MSE: 1.42981682767 -Train Accuracy: 0.848485\n",
      "epoch: 33 - cost: 0.337095 -MSE: 1.35973291445 -Train Accuracy: 0.836364\n",
      "epoch: 34 - cost: 0.325596 -MSE: 1.43103680132 -Train Accuracy: 0.854545\n",
      "epoch: 35 - cost: 0.336118 -MSE: 1.36048482571 -Train Accuracy: 0.836364\n",
      "epoch: 36 - cost: 0.324706 -MSE: 1.43228386739 -Train Accuracy: 0.860606\n",
      "epoch: 37 - cost: 0.33515 -MSE: 1.36127521496 -Train Accuracy: 0.836364\n",
      "epoch: 38 - cost: 0.323822 -MSE: 1.43355768717 -Train Accuracy: 0.860606\n",
      "epoch: 39 - cost: 0.33419 -MSE: 1.36210319209 -Train Accuracy: 0.836364\n",
      "epoch: 40 - cost: 0.322945 -MSE: 1.43485781659 -Train Accuracy: 0.860606\n",
      "epoch: 41 - cost: 0.333238 -MSE: 1.36296820672 -Train Accuracy: 0.836364\n",
      "epoch: 42 - cost: 0.322075 -MSE: 1.43618405084 -Train Accuracy: 0.866667\n",
      "epoch: 43 - cost: 0.332294 -MSE: 1.36386909633 -Train Accuracy: 0.836364\n",
      "epoch: 44 - cost: 0.321212 -MSE: 1.43753525192 -Train Accuracy: 0.866667\n",
      "epoch: 45 - cost: 0.331358 -MSE: 1.36480534341 -Train Accuracy: 0.836364\n",
      "epoch: 46 - cost: 0.320354 -MSE: 1.43891122902 -Train Accuracy: 0.866667\n",
      "epoch: 47 - cost: 0.330429 -MSE: 1.36577606893 -Train Accuracy: 0.836364\n",
      "epoch: 48 - cost: 0.319503 -MSE: 1.44031137657 -Train Accuracy: 0.872727\n",
      "epoch: 49 - cost: 0.329507 -MSE: 1.36677980893 -Train Accuracy: 0.836364\n",
      "epoch: 50 - cost: 0.318658 -MSE: 1.44173540685 -Train Accuracy: 0.872727\n",
      "epoch: 51 - cost: 0.328593 -MSE: 1.36781703424 -Train Accuracy: 0.836364\n",
      "epoch: 52 - cost: 0.317818 -MSE: 1.44318235995 -Train Accuracy: 0.872727\n",
      "epoch: 53 - cost: 0.327685 -MSE: 1.36888593501 -Train Accuracy: 0.836364\n",
      "epoch: 54 - cost: 0.316985 -MSE: 1.44465178092 -Train Accuracy: 0.872727\n",
      "epoch: 55 - cost: 0.326784 -MSE: 1.36998635154 -Train Accuracy: 0.836364\n",
      "epoch: 56 - cost: 0.316156 -MSE: 1.44614381942 -Train Accuracy: 0.872727\n",
      "epoch: 57 - cost: 0.32589 -MSE: 1.37111729823 -Train Accuracy: 0.836364\n",
      "epoch: 58 - cost: 0.315334 -MSE: 1.4476570009 -Train Accuracy: 0.872727\n",
      "epoch: 59 - cost: 0.325001 -MSE: 1.37227757704 -Train Accuracy: 0.836364\n",
      "epoch: 60 - cost: 0.314516 -MSE: 1.44919141357 -Train Accuracy: 0.872727\n",
      "epoch: 61 - cost: 0.324119 -MSE: 1.37346716276 -Train Accuracy: 0.836364\n",
      "epoch: 62 - cost: 0.313703 -MSE: 1.45074564191 -Train Accuracy: 0.872727\n",
      "epoch: 63 - cost: 0.323243 -MSE: 1.37468415685 -Train Accuracy: 0.836364\n",
      "epoch: 64 - cost: 0.312895 -MSE: 1.45232016925 -Train Accuracy: 0.872727\n",
      "epoch: 65 - cost: 0.322372 -MSE: 1.37592971196 -Train Accuracy: 0.836364\n",
      "epoch: 66 - cost: 0.312092 -MSE: 1.45391434845 -Train Accuracy: 0.872727\n",
      "epoch: 67 - cost: 0.321507 -MSE: 1.37720124914 -Train Accuracy: 0.836364\n",
      "epoch: 68 - cost: 0.311294 -MSE: 1.45552720143 -Train Accuracy: 0.872727\n",
      "epoch: 69 - cost: 0.320647 -MSE: 1.37849919412 -Train Accuracy: 0.836364\n",
      "epoch: 70 - cost: 0.3105 -MSE: 1.45715785567 -Train Accuracy: 0.872727\n",
      "epoch: 71 - cost: 0.319792 -MSE: 1.37982170107 -Train Accuracy: 0.836364\n",
      "epoch: 72 - cost: 0.30971 -MSE: 1.45880685102 -Train Accuracy: 0.872727\n",
      "epoch: 73 - cost: 0.318942 -MSE: 1.38116856175 -Train Accuracy: 0.836364\n",
      "epoch: 74 - cost: 0.308925 -MSE: 1.46047265595 -Train Accuracy: 0.872727\n",
      "epoch: 75 - cost: 0.318097 -MSE: 1.38254026102 -Train Accuracy: 0.836364\n",
      "epoch: 76 - cost: 0.308143 -MSE: 1.46215523958 -Train Accuracy: 0.872727\n",
      "epoch: 77 - cost: 0.317256 -MSE: 1.38393400961 -Train Accuracy: 0.836364\n",
      "epoch: 78 - cost: 0.307365 -MSE: 1.46385472189 -Train Accuracy: 0.872727\n",
      "epoch: 79 - cost: 0.31642 -MSE: 1.38535075867 -Train Accuracy: 0.836364\n",
      "epoch: 80 - cost: 0.306591 -MSE: 1.46556920757 -Train Accuracy: 0.872727\n",
      "epoch: 81 - cost: 0.315588 -MSE: 1.38678897561 -Train Accuracy: 0.836364\n",
      "epoch: 82 - cost: 0.305821 -MSE: 1.46729832549 -Train Accuracy: 0.872727\n",
      "epoch: 83 - cost: 0.31476 -MSE: 1.38824863987 -Train Accuracy: 0.836364\n",
      "epoch: 84 - cost: 0.305054 -MSE: 1.46904271008 -Train Accuracy: 0.872727\n",
      "epoch: 85 - cost: 0.313936 -MSE: 1.38972811415 -Train Accuracy: 0.836364\n",
      "epoch: 86 - cost: 0.30429 -MSE: 1.47080105349 -Train Accuracy: 0.872727\n",
      "epoch: 87 - cost: 0.313115 -MSE: 1.39122778399 -Train Accuracy: 0.836364\n",
      "epoch: 88 - cost: 0.303529 -MSE: 1.47257302468 -Train Accuracy: 0.872727\n",
      "epoch: 89 - cost: 0.312298 -MSE: 1.39274679708 -Train Accuracy: 0.836364\n",
      "epoch: 90 - cost: 0.302772 -MSE: 1.47435848037 -Train Accuracy: 0.872727\n",
      "epoch: 91 - cost: 0.311485 -MSE: 1.39428399985 -Train Accuracy: 0.836364\n",
      "epoch: 92 - cost: 0.302017 -MSE: 1.47615651215 -Train Accuracy: 0.872727\n",
      "epoch: 93 - cost: 0.310675 -MSE: 1.3958392192 -Train Accuracy: 0.836364\n",
      "epoch: 94 - cost: 0.301265 -MSE: 1.47796648706 -Train Accuracy: 0.872727\n",
      "epoch: 95 - cost: 0.309867 -MSE: 1.3974116735 -Train Accuracy: 0.836364\n",
      "epoch: 96 - cost: 0.300516 -MSE: 1.47978789362 -Train Accuracy: 0.872727\n",
      "epoch: 97 - cost: 0.309063 -MSE: 1.39900034298 -Train Accuracy: 0.836364\n",
      "epoch: 98 - cost: 0.299769 -MSE: 1.48162105924 -Train Accuracy: 0.872727\n",
      "epoch: 99 - cost: 0.308262 -MSE: 1.40060595087 -Train Accuracy: 0.836364\n",
      "epoch: 100 - cost: 0.299025 -MSE: 1.48346495864 -Train Accuracy: 0.872727\n",
      "epoch: 101 - cost: 0.307463 -MSE: 1.40222670331 -Train Accuracy: 0.836364\n",
      "epoch: 102 - cost: 0.298283 -MSE: 1.48531874667 -Train Accuracy: 0.872727\n",
      "epoch: 103 - cost: 0.306666 -MSE: 1.40386206842 -Train Accuracy: 0.836364\n",
      "epoch: 104 - cost: 0.297543 -MSE: 1.48718259721 -Train Accuracy: 0.878788\n",
      "epoch: 105 - cost: 0.305872 -MSE: 1.40551235435 -Train Accuracy: 0.836364\n",
      "epoch: 106 - cost: 0.296805 -MSE: 1.4890560317 -Train Accuracy: 0.878788\n",
      "epoch: 107 - cost: 0.30508 -MSE: 1.40717628031 -Train Accuracy: 0.836364\n",
      "epoch: 108 - cost: 0.296069 -MSE: 1.49093769432 -Train Accuracy: 0.878788\n",
      "epoch: 109 - cost: 0.30429 -MSE: 1.40885301556 -Train Accuracy: 0.836364\n",
      "epoch: 110 - cost: 0.295335 -MSE: 1.49282893318 -Train Accuracy: 0.878788\n",
      "epoch: 111 - cost: 0.303502 -MSE: 1.41054397651 -Train Accuracy: 0.836364\n",
      "epoch: 112 - cost: 0.294603 -MSE: 1.49472794544 -Train Accuracy: 0.878788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113 - cost: 0.302716 -MSE: 1.41224638921 -Train Accuracy: 0.836364\n",
      "epoch: 114 - cost: 0.293873 -MSE: 1.49663504631 -Train Accuracy: 0.878788\n",
      "epoch: 115 - cost: 0.301932 -MSE: 1.41396088651 -Train Accuracy: 0.836364\n",
      "epoch: 116 - cost: 0.293143 -MSE: 1.49854911593 -Train Accuracy: 0.878788\n",
      "epoch: 117 - cost: 0.301149 -MSE: 1.41568721904 -Train Accuracy: 0.836364\n",
      "epoch: 118 - cost: 0.292416 -MSE: 1.50047048146 -Train Accuracy: 0.878788\n",
      "epoch: 119 - cost: 0.300368 -MSE: 1.41742371122 -Train Accuracy: 0.836364\n",
      "epoch: 120 - cost: 0.291689 -MSE: 1.5023985912 -Train Accuracy: 0.878788\n",
      "epoch: 121 - cost: 0.299587 -MSE: 1.41917178565 -Train Accuracy: 0.836364\n",
      "epoch: 122 - cost: 0.290964 -MSE: 1.50433329767 -Train Accuracy: 0.878788\n",
      "epoch: 123 - cost: 0.298809 -MSE: 1.42092958998 -Train Accuracy: 0.836364\n",
      "epoch: 124 - cost: 0.29024 -MSE: 1.50627367027 -Train Accuracy: 0.878788\n",
      "epoch: 125 - cost: 0.298031 -MSE: 1.42269686451 -Train Accuracy: 0.836364\n",
      "epoch: 126 - cost: 0.289517 -MSE: 1.50822009572 -Train Accuracy: 0.878788\n",
      "epoch: 127 - cost: 0.297254 -MSE: 1.42447426087 -Train Accuracy: 0.836364\n",
      "epoch: 128 - cost: 0.288796 -MSE: 1.51017097459 -Train Accuracy: 0.878788\n",
      "epoch: 129 - cost: 0.296478 -MSE: 1.42625965005 -Train Accuracy: 0.836364\n",
      "epoch: 130 - cost: 0.288074 -MSE: 1.51212740795 -Train Accuracy: 0.878788\n",
      "epoch: 131 - cost: 0.295703 -MSE: 1.42805417264 -Train Accuracy: 0.836364\n",
      "epoch: 132 - cost: 0.287354 -MSE: 1.51408812579 -Train Accuracy: 0.878788\n",
      "epoch: 133 - cost: 0.294929 -MSE: 1.42985614064 -Train Accuracy: 0.836364\n",
      "epoch: 134 - cost: 0.286635 -MSE: 1.51605344534 -Train Accuracy: 0.878788\n",
      "epoch: 135 - cost: 0.294155 -MSE: 1.43166592215 -Train Accuracy: 0.836364\n",
      "epoch: 136 - cost: 0.285916 -MSE: 1.51802210945 -Train Accuracy: 0.878788\n",
      "epoch: 137 - cost: 0.293382 -MSE: 1.43348304698 -Train Accuracy: 0.836364\n",
      "epoch: 138 - cost: 0.285198 -MSE: 1.51999522049 -Train Accuracy: 0.878788\n",
      "epoch: 139 - cost: 0.292609 -MSE: 1.43530780704 -Train Accuracy: 0.836364\n",
      "epoch: 140 - cost: 0.28448 -MSE: 1.52197137241 -Train Accuracy: 0.878788\n",
      "epoch: 141 - cost: 0.291837 -MSE: 1.43713881823 -Train Accuracy: 0.836364\n",
      "epoch: 142 - cost: 0.283762 -MSE: 1.52395133875 -Train Accuracy: 0.878788\n",
      "epoch: 143 - cost: 0.291065 -MSE: 1.43897605124 -Train Accuracy: 0.836364\n",
      "epoch: 144 - cost: 0.283045 -MSE: 1.52593408457 -Train Accuracy: 0.878788\n",
      "epoch: 145 - cost: 0.290293 -MSE: 1.44081996627 -Train Accuracy: 0.836364\n",
      "epoch: 146 - cost: 0.282329 -MSE: 1.52791883856 -Train Accuracy: 0.878788\n",
      "epoch: 147 - cost: 0.289521 -MSE: 1.44266928949 -Train Accuracy: 0.836364\n",
      "epoch: 148 - cost: 0.281612 -MSE: 1.5299065991 -Train Accuracy: 0.878788\n",
      "epoch: 149 - cost: 0.288749 -MSE: 1.44452433658 -Train Accuracy: 0.836364\n",
      "epoch: 150 - cost: 0.280896 -MSE: 1.53189650263 -Train Accuracy: 0.878788\n",
      "epoch: 151 - cost: 0.287977 -MSE: 1.44638421806 -Train Accuracy: 0.836364\n",
      "epoch: 152 - cost: 0.28018 -MSE: 1.53388788453 -Train Accuracy: 0.878788\n",
      "epoch: 153 - cost: 0.287205 -MSE: 1.44824955246 -Train Accuracy: 0.836364\n",
      "epoch: 154 - cost: 0.279463 -MSE: 1.53588185113 -Train Accuracy: 0.884848\n",
      "epoch: 155 - cost: 0.286433 -MSE: 1.45011944171 -Train Accuracy: 0.836364\n",
      "epoch: 156 - cost: 0.278747 -MSE: 1.53787674419 -Train Accuracy: 0.890909\n",
      "epoch: 157 - cost: 0.285661 -MSE: 1.45199346452 -Train Accuracy: 0.836364\n",
      "epoch: 158 - cost: 0.278031 -MSE: 1.53987343388 -Train Accuracy: 0.890909\n",
      "epoch: 159 - cost: 0.284888 -MSE: 1.4538726235 -Train Accuracy: 0.842424\n",
      "epoch: 160 - cost: 0.277315 -MSE: 1.5418709667 -Train Accuracy: 0.89697\n",
      "epoch: 161 - cost: 0.284115 -MSE: 1.45575466527 -Train Accuracy: 0.842424\n",
      "epoch: 162 - cost: 0.276598 -MSE: 1.54386998054 -Train Accuracy: 0.89697\n",
      "epoch: 163 - cost: 0.283342 -MSE: 1.45764167101 -Train Accuracy: 0.842424\n",
      "epoch: 164 - cost: 0.275882 -MSE: 1.54586928153 -Train Accuracy: 0.89697\n",
      "epoch: 165 - cost: 0.282568 -MSE: 1.45953189833 -Train Accuracy: 0.842424\n",
      "epoch: 166 - cost: 0.275165 -MSE: 1.54786953835 -Train Accuracy: 0.89697\n",
      "epoch: 167 - cost: 0.281794 -MSE: 1.46142538523 -Train Accuracy: 0.842424\n",
      "epoch: 168 - cost: 0.274447 -MSE: 1.54986964558 -Train Accuracy: 0.89697\n",
      "epoch: 169 - cost: 0.281019 -MSE: 1.46332210986 -Train Accuracy: 0.842424\n",
      "epoch: 170 - cost: 0.27373 -MSE: 1.55187026161 -Train Accuracy: 0.89697\n",
      "epoch: 171 - cost: 0.280244 -MSE: 1.46522150121 -Train Accuracy: 0.842424\n",
      "epoch: 172 - cost: 0.273012 -MSE: 1.5538712602 -Train Accuracy: 0.89697\n",
      "epoch: 173 - cost: 0.279468 -MSE: 1.46712427845 -Train Accuracy: 0.842424\n",
      "epoch: 174 - cost: 0.272293 -MSE: 1.55587229103 -Train Accuracy: 0.89697\n",
      "epoch: 175 - cost: 0.278691 -MSE: 1.46902964488 -Train Accuracy: 0.842424\n",
      "epoch: 176 - cost: 0.271574 -MSE: 1.557872542 -Train Accuracy: 0.89697\n",
      "epoch: 177 - cost: 0.277914 -MSE: 1.47093728193 -Train Accuracy: 0.842424\n",
      "epoch: 178 - cost: 0.270855 -MSE: 1.55987306915 -Train Accuracy: 0.89697\n",
      "epoch: 179 - cost: 0.277136 -MSE: 1.47284721934 -Train Accuracy: 0.842424\n",
      "epoch: 180 - cost: 0.270135 -MSE: 1.56187337355 -Train Accuracy: 0.89697\n",
      "epoch: 181 - cost: 0.276357 -MSE: 1.47476006193 -Train Accuracy: 0.842424\n",
      "epoch: 182 - cost: 0.269415 -MSE: 1.56387292549 -Train Accuracy: 0.89697\n",
      "epoch: 183 - cost: 0.275577 -MSE: 1.47667490896 -Train Accuracy: 0.842424\n",
      "epoch: 184 - cost: 0.268694 -MSE: 1.56587163388 -Train Accuracy: 0.89697\n",
      "epoch: 185 - cost: 0.274797 -MSE: 1.47859207438 -Train Accuracy: 0.842424\n",
      "epoch: 186 - cost: 0.267972 -MSE: 1.56787023958 -Train Accuracy: 0.89697\n",
      "epoch: 187 - cost: 0.274016 -MSE: 1.48051122933 -Train Accuracy: 0.848485\n",
      "epoch: 188 - cost: 0.26725 -MSE: 1.56986776293 -Train Accuracy: 0.89697\n",
      "epoch: 189 - cost: 0.273234 -MSE: 1.48243248849 -Train Accuracy: 0.848485\n",
      "epoch: 190 - cost: 0.266527 -MSE: 1.57186540903 -Train Accuracy: 0.89697\n",
      "epoch: 191 - cost: 0.27245 -MSE: 1.4843555257 -Train Accuracy: 0.848485\n",
      "epoch: 192 - cost: 0.265803 -MSE: 1.57386146272 -Train Accuracy: 0.89697\n",
      "epoch: 193 - cost: 0.271667 -MSE: 1.48628070289 -Train Accuracy: 0.848485\n",
      "epoch: 194 - cost: 0.265079 -MSE: 1.57585735935 -Train Accuracy: 0.89697\n",
      "epoch: 195 - cost: 0.270882 -MSE: 1.48820776765 -Train Accuracy: 0.848485\n",
      "epoch: 196 - cost: 0.264354 -MSE: 1.57785220415 -Train Accuracy: 0.89697\n",
      "epoch: 197 - cost: 0.270096 -MSE: 1.49013651826 -Train Accuracy: 0.848485\n",
      "epoch: 198 - cost: 0.263629 -MSE: 1.57984577273 -Train Accuracy: 0.89697\n",
      "epoch: 199 - cost: 0.26931 -MSE: 1.49206694129 -Train Accuracy: 0.848485\n",
      "epoch: 200 - cost: 0.262902 -MSE: 1.58183846375 -Train Accuracy: 0.89697\n",
      "epoch: 201 - cost: 0.268523 -MSE: 1.49399888679 -Train Accuracy: 0.848485\n",
      "epoch: 202 - cost: 0.262176 -MSE: 1.58383041247 -Train Accuracy: 0.89697\n",
      "epoch: 203 - cost: 0.267734 -MSE: 1.49593278981 -Train Accuracy: 0.848485\n",
      "epoch: 204 - cost: 0.261448 -MSE: 1.58582098725 -Train Accuracy: 0.89697\n",
      "epoch: 205 - cost: 0.266945 -MSE: 1.49786873961 -Train Accuracy: 0.848485\n",
      "epoch: 206 - cost: 0.260719 -MSE: 1.58781096141 -Train Accuracy: 0.89697\n",
      "epoch: 207 - cost: 0.266155 -MSE: 1.49980592872 -Train Accuracy: 0.848485\n",
      "epoch: 208 - cost: 0.25999 -MSE: 1.58979993157 -Train Accuracy: 0.89697\n",
      "epoch: 209 - cost: 0.265364 -MSE: 1.50174559738 -Train Accuracy: 0.848485\n",
      "epoch: 210 - cost: 0.25926 -MSE: 1.59178785246 -Train Accuracy: 0.89697\n",
      "epoch: 211 - cost: 0.264572 -MSE: 1.50368633907 -Train Accuracy: 0.848485\n",
      "epoch: 212 - cost: 0.25853 -MSE: 1.59377474703 -Train Accuracy: 0.89697\n",
      "epoch: 213 - cost: 0.26378 -MSE: 1.5056294225 -Train Accuracy: 0.848485\n",
      "epoch: 214 - cost: 0.257798 -MSE: 1.59576082018 -Train Accuracy: 0.89697\n",
      "epoch: 215 - cost: 0.262986 -MSE: 1.50757512591 -Train Accuracy: 0.854545\n",
      "epoch: 216 - cost: 0.257066 -MSE: 1.59774608425 -Train Accuracy: 0.89697\n",
      "epoch: 217 - cost: 0.262192 -MSE: 1.50952207512 -Train Accuracy: 0.854545\n",
      "epoch: 218 - cost: 0.256334 -MSE: 1.59973041735 -Train Accuracy: 0.89697\n",
      "epoch: 219 - cost: 0.261397 -MSE: 1.51147133402 -Train Accuracy: 0.860606\n",
      "epoch: 220 - cost: 0.2556 -MSE: 1.6017144724 -Train Accuracy: 0.890909\n",
      "epoch: 221 - cost: 0.260601 -MSE: 1.51342274712 -Train Accuracy: 0.860606\n",
      "epoch: 222 - cost: 0.254866 -MSE: 1.60369789107 -Train Accuracy: 0.890909\n",
      "epoch: 223 - cost: 0.259804 -MSE: 1.51537672233 -Train Accuracy: 0.860606\n",
      "epoch: 224 - cost: 0.254131 -MSE: 1.60567955363 -Train Accuracy: 0.890909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 225 - cost: 0.259007 -MSE: 1.51733262911 -Train Accuracy: 0.860606\n",
      "epoch: 226 - cost: 0.253395 -MSE: 1.60766146374 -Train Accuracy: 0.890909\n",
      "epoch: 227 - cost: 0.258209 -MSE: 1.5192906865 -Train Accuracy: 0.860606\n",
      "epoch: 228 - cost: 0.252659 -MSE: 1.60964234661 -Train Accuracy: 0.89697\n",
      "epoch: 229 - cost: 0.25741 -MSE: 1.52125137299 -Train Accuracy: 0.860606\n",
      "epoch: 230 - cost: 0.251922 -MSE: 1.61162314828 -Train Accuracy: 0.90303\n",
      "epoch: 231 - cost: 0.256611 -MSE: 1.52321519339 -Train Accuracy: 0.860606\n",
      "epoch: 232 - cost: 0.251185 -MSE: 1.61360391267 -Train Accuracy: 0.90303\n",
      "epoch: 233 - cost: 0.255811 -MSE: 1.52518161551 -Train Accuracy: 0.860606\n",
      "epoch: 234 - cost: 0.250447 -MSE: 1.61558406171 -Train Accuracy: 0.90303\n",
      "epoch: 235 - cost: 0.25501 -MSE: 1.5271511882 -Train Accuracy: 0.860606\n",
      "epoch: 236 - cost: 0.249708 -MSE: 1.61756421359 -Train Accuracy: 0.90303\n",
      "epoch: 237 - cost: 0.254209 -MSE: 1.52912390296 -Train Accuracy: 0.860606\n",
      "epoch: 238 - cost: 0.248969 -MSE: 1.61954415065 -Train Accuracy: 0.90303\n",
      "epoch: 239 - cost: 0.253407 -MSE: 1.53110031693 -Train Accuracy: 0.866667\n",
      "epoch: 240 - cost: 0.24823 -MSE: 1.62152523943 -Train Accuracy: 0.90303\n",
      "epoch: 241 - cost: 0.252605 -MSE: 1.53308014927 -Train Accuracy: 0.866667\n",
      "epoch: 242 - cost: 0.24749 -MSE: 1.62350577711 -Train Accuracy: 0.90303\n",
      "epoch: 243 - cost: 0.251802 -MSE: 1.53506309337 -Train Accuracy: 0.866667\n",
      "epoch: 244 - cost: 0.246749 -MSE: 1.62548657449 -Train Accuracy: 0.90303\n",
      "epoch: 245 - cost: 0.251 -MSE: 1.53704986645 -Train Accuracy: 0.866667\n",
      "epoch: 246 - cost: 0.246008 -MSE: 1.62746832579 -Train Accuracy: 0.909091\n",
      "epoch: 247 - cost: 0.250196 -MSE: 1.53904105097 -Train Accuracy: 0.866667\n",
      "epoch: 248 - cost: 0.245267 -MSE: 1.62945021221 -Train Accuracy: 0.909091\n",
      "epoch: 249 - cost: 0.249393 -MSE: 1.54103527775 -Train Accuracy: 0.866667\n",
      "epoch: 250 - cost: 0.244525 -MSE: 1.63143326293 -Train Accuracy: 0.909091\n",
      "epoch: 251 - cost: 0.248589 -MSE: 1.54303519374 -Train Accuracy: 0.866667\n",
      "epoch: 252 - cost: 0.243783 -MSE: 1.63341651357 -Train Accuracy: 0.909091\n",
      "epoch: 253 - cost: 0.247785 -MSE: 1.5450389507 -Train Accuracy: 0.866667\n",
      "epoch: 254 - cost: 0.243041 -MSE: 1.63540149265 -Train Accuracy: 0.909091\n",
      "epoch: 255 - cost: 0.246981 -MSE: 1.5470474856 -Train Accuracy: 0.866667\n",
      "epoch: 256 - cost: 0.242298 -MSE: 1.6373875639 -Train Accuracy: 0.909091\n",
      "epoch: 257 - cost: 0.246177 -MSE: 1.54906128376 -Train Accuracy: 0.866667\n",
      "epoch: 258 - cost: 0.241555 -MSE: 1.63937542505 -Train Accuracy: 0.909091\n",
      "epoch: 259 - cost: 0.245372 -MSE: 1.55108088357 -Train Accuracy: 0.872727\n",
      "epoch: 260 - cost: 0.240812 -MSE: 1.64136496933 -Train Accuracy: 0.909091\n",
      "epoch: 261 - cost: 0.244568 -MSE: 1.5531055884 -Train Accuracy: 0.872727\n",
      "epoch: 262 - cost: 0.240069 -MSE: 1.64335595729 -Train Accuracy: 0.909091\n",
      "epoch: 263 - cost: 0.243764 -MSE: 1.55513574023 -Train Accuracy: 0.872727\n",
      "epoch: 264 - cost: 0.239326 -MSE: 1.64534931918 -Train Accuracy: 0.909091\n",
      "epoch: 265 - cost: 0.24296 -MSE: 1.55717159387 -Train Accuracy: 0.884848\n",
      "epoch: 266 - cost: 0.238582 -MSE: 1.64734417561 -Train Accuracy: 0.909091\n",
      "epoch: 267 - cost: 0.242157 -MSE: 1.55921404796 -Train Accuracy: 0.884848\n",
      "epoch: 268 - cost: 0.237839 -MSE: 1.6493416333 -Train Accuracy: 0.909091\n",
      "epoch: 269 - cost: 0.241353 -MSE: 1.56126288336 -Train Accuracy: 0.884848\n",
      "epoch: 270 - cost: 0.237096 -MSE: 1.65134179028 -Train Accuracy: 0.909091\n",
      "epoch: 271 - cost: 0.24055 -MSE: 1.56331864156 -Train Accuracy: 0.884848\n",
      "epoch: 272 - cost: 0.236353 -MSE: 1.65334506004 -Train Accuracy: 0.909091\n",
      "epoch: 273 - cost: 0.239748 -MSE: 1.56538113334 -Train Accuracy: 0.884848\n",
      "epoch: 274 - cost: 0.23561 -MSE: 1.65535075841 -Train Accuracy: 0.909091\n",
      "epoch: 275 - cost: 0.238945 -MSE: 1.56745062266 -Train Accuracy: 0.884848\n",
      "epoch: 276 - cost: 0.234867 -MSE: 1.6573594575 -Train Accuracy: 0.909091\n",
      "epoch: 277 - cost: 0.238144 -MSE: 1.56952822574 -Train Accuracy: 0.884848\n",
      "epoch: 278 - cost: 0.234124 -MSE: 1.65937230251 -Train Accuracy: 0.909091\n",
      "epoch: 279 - cost: 0.237342 -MSE: 1.57161344397 -Train Accuracy: 0.884848\n",
      "epoch: 280 - cost: 0.233382 -MSE: 1.6613882308 -Train Accuracy: 0.909091\n",
      "epoch: 281 - cost: 0.236542 -MSE: 1.57370592522 -Train Accuracy: 0.884848\n",
      "epoch: 282 - cost: 0.23264 -MSE: 1.6634079116 -Train Accuracy: 0.909091\n",
      "epoch: 283 - cost: 0.235742 -MSE: 1.57580677385 -Train Accuracy: 0.884848\n",
      "epoch: 284 - cost: 0.231899 -MSE: 1.66543190345 -Train Accuracy: 0.909091\n",
      "epoch: 285 - cost: 0.234943 -MSE: 1.57791665703 -Train Accuracy: 0.884848\n",
      "epoch: 286 - cost: 0.231158 -MSE: 1.66745994412 -Train Accuracy: 0.915152\n",
      "epoch: 287 - cost: 0.234145 -MSE: 1.58003524023 -Train Accuracy: 0.884848\n",
      "epoch: 288 - cost: 0.230417 -MSE: 1.66949275433 -Train Accuracy: 0.915152\n",
      "epoch: 289 - cost: 0.233348 -MSE: 1.58216335311 -Train Accuracy: 0.890909\n",
      "epoch: 290 - cost: 0.229677 -MSE: 1.67152985846 -Train Accuracy: 0.915152\n",
      "epoch: 291 - cost: 0.232551 -MSE: 1.58429997546 -Train Accuracy: 0.890909\n",
      "epoch: 292 - cost: 0.228938 -MSE: 1.6735725926 -Train Accuracy: 0.915152\n",
      "epoch: 293 - cost: 0.231756 -MSE: 1.58644694511 -Train Accuracy: 0.890909\n",
      "epoch: 294 - cost: 0.228199 -MSE: 1.67562008934 -Train Accuracy: 0.915152\n",
      "epoch: 295 - cost: 0.230962 -MSE: 1.58860376118 -Train Accuracy: 0.890909\n",
      "epoch: 296 - cost: 0.227461 -MSE: 1.67767337362 -Train Accuracy: 0.915152\n",
      "epoch: 297 - cost: 0.230169 -MSE: 1.5907709236 -Train Accuracy: 0.890909\n",
      "epoch: 298 - cost: 0.226724 -MSE: 1.67973262432 -Train Accuracy: 0.915152\n",
      "epoch: 299 - cost: 0.229378 -MSE: 1.59294866307 -Train Accuracy: 0.890909\n",
      "epoch: 300 - cost: 0.225987 -MSE: 1.68179717424 -Train Accuracy: 0.915152\n",
      "epoch: 301 - cost: 0.228588 -MSE: 1.59513704126 -Train Accuracy: 0.890909\n",
      "epoch: 302 - cost: 0.225252 -MSE: 1.68386848443 -Train Accuracy: 0.915152\n",
      "epoch: 303 - cost: 0.227799 -MSE: 1.59733691678 -Train Accuracy: 0.890909\n",
      "epoch: 304 - cost: 0.224517 -MSE: 1.68594613902 -Train Accuracy: 0.915152\n",
      "epoch: 305 - cost: 0.227011 -MSE: 1.59954785582 -Train Accuracy: 0.890909\n",
      "epoch: 306 - cost: 0.223784 -MSE: 1.68803056983 -Train Accuracy: 0.915152\n",
      "epoch: 307 - cost: 0.226225 -MSE: 1.60177080089 -Train Accuracy: 0.890909\n",
      "epoch: 308 - cost: 0.223051 -MSE: 1.69012215631 -Train Accuracy: 0.915152\n",
      "epoch: 309 - cost: 0.225441 -MSE: 1.60400630801 -Train Accuracy: 0.890909\n",
      "epoch: 310 - cost: 0.22232 -MSE: 1.69222162375 -Train Accuracy: 0.915152\n",
      "epoch: 311 - cost: 0.224659 -MSE: 1.60625384059 -Train Accuracy: 0.89697\n",
      "epoch: 312 - cost: 0.22159 -MSE: 1.69432864065 -Train Accuracy: 0.915152\n",
      "epoch: 313 - cost: 0.223878 -MSE: 1.60851422169 -Train Accuracy: 0.89697\n",
      "epoch: 314 - cost: 0.220861 -MSE: 1.69644293938 -Train Accuracy: 0.915152\n",
      "epoch: 315 - cost: 0.223099 -MSE: 1.61078705357 -Train Accuracy: 0.89697\n",
      "epoch: 316 - cost: 0.220134 -MSE: 1.69856533259 -Train Accuracy: 0.915152\n",
      "epoch: 317 - cost: 0.222322 -MSE: 1.61307273442 -Train Accuracy: 0.89697\n",
      "epoch: 318 - cost: 0.219407 -MSE: 1.700696255 -Train Accuracy: 0.921212\n",
      "epoch: 319 - cost: 0.221547 -MSE: 1.61537249434 -Train Accuracy: 0.89697\n",
      "epoch: 320 - cost: 0.218683 -MSE: 1.70283604997 -Train Accuracy: 0.921212\n",
      "epoch: 321 - cost: 0.220774 -MSE: 1.61768609887 -Train Accuracy: 0.89697\n",
      "epoch: 322 - cost: 0.21796 -MSE: 1.70498447062 -Train Accuracy: 0.921212\n",
      "epoch: 323 - cost: 0.220003 -MSE: 1.62001324747 -Train Accuracy: 0.90303\n",
      "epoch: 324 - cost: 0.217238 -MSE: 1.70714248498 -Train Accuracy: 0.921212\n",
      "epoch: 325 - cost: 0.219234 -MSE: 1.6223554046 -Train Accuracy: 0.90303\n",
      "epoch: 326 - cost: 0.216518 -MSE: 1.70931018256 -Train Accuracy: 0.921212\n",
      "epoch: 327 - cost: 0.218467 -MSE: 1.62471192159 -Train Accuracy: 0.90303\n",
      "epoch: 328 - cost: 0.2158 -MSE: 1.71148778755 -Train Accuracy: 0.921212\n",
      "epoch: 329 - cost: 0.217703 -MSE: 1.62708333551 -Train Accuracy: 0.90303\n",
      "epoch: 330 - cost: 0.215083 -MSE: 1.71367504302 -Train Accuracy: 0.921212\n",
      "epoch: 331 - cost: 0.216941 -MSE: 1.62946969339 -Train Accuracy: 0.90303\n",
      "epoch: 332 - cost: 0.214368 -MSE: 1.71587277232 -Train Accuracy: 0.921212\n",
      "epoch: 333 - cost: 0.216182 -MSE: 1.63187184531 -Train Accuracy: 0.90303\n",
      "epoch: 334 - cost: 0.213655 -MSE: 1.7180814779 -Train Accuracy: 0.921212\n",
      "epoch: 335 - cost: 0.215425 -MSE: 1.63428966549 -Train Accuracy: 0.909091\n",
      "epoch: 336 - cost: 0.212944 -MSE: 1.72030089234 -Train Accuracy: 0.921212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 337 - cost: 0.21467 -MSE: 1.63672343511 -Train Accuracy: 0.909091\n",
      "epoch: 338 - cost: 0.212235 -MSE: 1.72253124066 -Train Accuracy: 0.921212\n",
      "epoch: 339 - cost: 0.213918 -MSE: 1.63917333774 -Train Accuracy: 0.909091\n",
      "epoch: 340 - cost: 0.211528 -MSE: 1.72477398438 -Train Accuracy: 0.921212\n",
      "epoch: 341 - cost: 0.213169 -MSE: 1.641639677 -Train Accuracy: 0.909091\n",
      "epoch: 342 - cost: 0.210823 -MSE: 1.72702766083 -Train Accuracy: 0.921212\n",
      "epoch: 343 - cost: 0.212423 -MSE: 1.64412268109 -Train Accuracy: 0.909091\n",
      "epoch: 344 - cost: 0.210121 -MSE: 1.72929378642 -Train Accuracy: 0.921212\n",
      "epoch: 345 - cost: 0.211679 -MSE: 1.6466233034 -Train Accuracy: 0.909091\n",
      "epoch: 346 - cost: 0.20942 -MSE: 1.73157264053 -Train Accuracy: 0.921212\n",
      "epoch: 347 - cost: 0.210938 -MSE: 1.64914074266 -Train Accuracy: 0.909091\n",
      "epoch: 348 - cost: 0.208722 -MSE: 1.73386363409 -Train Accuracy: 0.921212\n",
      "epoch: 349 - cost: 0.2102 -MSE: 1.6516760366 -Train Accuracy: 0.909091\n",
      "epoch: 350 - cost: 0.208025 -MSE: 1.73616771903 -Train Accuracy: 0.921212\n",
      "epoch: 351 - cost: 0.209465 -MSE: 1.65422821378 -Train Accuracy: 0.909091\n",
      "epoch: 352 - cost: 0.207332 -MSE: 1.73848557022 -Train Accuracy: 0.921212\n",
      "epoch: 353 - cost: 0.208733 -MSE: 1.65679841103 -Train Accuracy: 0.915152\n",
      "epoch: 354 - cost: 0.20664 -MSE: 1.74081606212 -Train Accuracy: 0.921212\n",
      "epoch: 355 - cost: 0.208004 -MSE: 1.65938696952 -Train Accuracy: 0.915152\n",
      "epoch: 356 - cost: 0.205952 -MSE: 1.74316081139 -Train Accuracy: 0.921212\n",
      "epoch: 357 - cost: 0.207278 -MSE: 1.66199378479 -Train Accuracy: 0.915152\n",
      "epoch: 358 - cost: 0.205265 -MSE: 1.74551924097 -Train Accuracy: 0.921212\n",
      "epoch: 359 - cost: 0.206556 -MSE: 1.66461908775 -Train Accuracy: 0.921212\n",
      "epoch: 360 - cost: 0.204581 -MSE: 1.74789229617 -Train Accuracy: 0.921212\n",
      "epoch: 361 - cost: 0.205836 -MSE: 1.66726339736 -Train Accuracy: 0.921212\n",
      "epoch: 362 - cost: 0.2039 -MSE: 1.75028023479 -Train Accuracy: 0.921212\n",
      "epoch: 363 - cost: 0.20512 -MSE: 1.66992633139 -Train Accuracy: 0.921212\n",
      "epoch: 364 - cost: 0.203222 -MSE: 1.75268269287 -Train Accuracy: 0.921212\n",
      "epoch: 365 - cost: 0.204407 -MSE: 1.67260874317 -Train Accuracy: 0.921212\n",
      "epoch: 366 - cost: 0.202546 -MSE: 1.7551005378 -Train Accuracy: 0.921212\n",
      "epoch: 367 - cost: 0.203698 -MSE: 1.67530972301 -Train Accuracy: 0.921212\n",
      "epoch: 368 - cost: 0.201873 -MSE: 1.75753357547 -Train Accuracy: 0.921212\n",
      "epoch: 369 - cost: 0.202992 -MSE: 1.67803050954 -Train Accuracy: 0.921212\n",
      "epoch: 370 - cost: 0.201202 -MSE: 1.7599825162 -Train Accuracy: 0.921212\n",
      "epoch: 371 - cost: 0.202289 -MSE: 1.68077154831 -Train Accuracy: 0.921212\n",
      "epoch: 372 - cost: 0.200535 -MSE: 1.76244775439 -Train Accuracy: 0.921212\n",
      "epoch: 373 - cost: 0.20159 -MSE: 1.68353190771 -Train Accuracy: 0.927273\n",
      "epoch: 374 - cost: 0.19987 -MSE: 1.76492850973 -Train Accuracy: 0.921212\n",
      "epoch: 375 - cost: 0.200894 -MSE: 1.68631160022 -Train Accuracy: 0.927273\n",
      "epoch: 376 - cost: 0.199208 -MSE: 1.767425959 -Train Accuracy: 0.921212\n",
      "epoch: 377 - cost: 0.200202 -MSE: 1.68911184863 -Train Accuracy: 0.927273\n",
      "epoch: 378 - cost: 0.19855 -MSE: 1.76994085221 -Train Accuracy: 0.921212\n",
      "epoch: 379 - cost: 0.199513 -MSE: 1.69193327855 -Train Accuracy: 0.927273\n",
      "epoch: 380 - cost: 0.197894 -MSE: 1.77247249983 -Train Accuracy: 0.921212\n",
      "epoch: 381 - cost: 0.198828 -MSE: 1.69477402078 -Train Accuracy: 0.927273\n",
      "epoch: 382 - cost: 0.197241 -MSE: 1.77502096131 -Train Accuracy: 0.921212\n",
      "epoch: 383 - cost: 0.198147 -MSE: 1.69763552103 -Train Accuracy: 0.933333\n",
      "epoch: 384 - cost: 0.196591 -MSE: 1.77758696154 -Train Accuracy: 0.921212\n",
      "epoch: 385 - cost: 0.197469 -MSE: 1.70051746303 -Train Accuracy: 0.933333\n",
      "epoch: 386 - cost: 0.195944 -MSE: 1.78017080616 -Train Accuracy: 0.927273\n",
      "epoch: 387 - cost: 0.196795 -MSE: 1.70342017067 -Train Accuracy: 0.933333\n",
      "epoch: 388 - cost: 0.195301 -MSE: 1.78277268911 -Train Accuracy: 0.927273\n",
      "epoch: 389 - cost: 0.196125 -MSE: 1.70634358106 -Train Accuracy: 0.933333\n",
      "epoch: 390 - cost: 0.19466 -MSE: 1.7853926274 -Train Accuracy: 0.927273\n",
      "epoch: 391 - cost: 0.195458 -MSE: 1.70928744613 -Train Accuracy: 0.933333\n",
      "epoch: 392 - cost: 0.194023 -MSE: 1.78803107246 -Train Accuracy: 0.927273\n",
      "epoch: 393 - cost: 0.194795 -MSE: 1.7122526574 -Train Accuracy: 0.933333\n",
      "epoch: 394 - cost: 0.193389 -MSE: 1.7906879209 -Train Accuracy: 0.933333\n",
      "epoch: 395 - cost: 0.194136 -MSE: 1.71523898619 -Train Accuracy: 0.933333\n",
      "epoch: 396 - cost: 0.192758 -MSE: 1.79336331481 -Train Accuracy: 0.933333\n",
      "epoch: 397 - cost: 0.193481 -MSE: 1.7182465723 -Train Accuracy: 0.933333\n",
      "epoch: 398 - cost: 0.19213 -MSE: 1.7960581156 -Train Accuracy: 0.933333\n",
      "epoch: 399 - cost: 0.192829 -MSE: 1.72127473489 -Train Accuracy: 0.933333\n",
      "epoch: 400 - cost: 0.191506 -MSE: 1.79877216857 -Train Accuracy: 0.933333\n",
      "epoch: 401 - cost: 0.192182 -MSE: 1.72432431561 -Train Accuracy: 0.933333\n",
      "epoch: 402 - cost: 0.190885 -MSE: 1.80150582576 -Train Accuracy: 0.933333\n",
      "epoch: 403 - cost: 0.191538 -MSE: 1.72739529498 -Train Accuracy: 0.933333\n",
      "epoch: 404 - cost: 0.190267 -MSE: 1.80425915427 -Train Accuracy: 0.933333\n",
      "epoch: 405 - cost: 0.190898 -MSE: 1.73048742955 -Train Accuracy: 0.933333\n",
      "epoch: 406 - cost: 0.189652 -MSE: 1.80703187925 -Train Accuracy: 0.933333\n",
      "epoch: 407 - cost: 0.190262 -MSE: 1.7336002788 -Train Accuracy: 0.933333\n",
      "epoch: 408 - cost: 0.189041 -MSE: 1.80982518554 -Train Accuracy: 0.933333\n",
      "epoch: 409 - cost: 0.18963 -MSE: 1.7367350795 -Train Accuracy: 0.933333\n",
      "epoch: 410 - cost: 0.188433 -MSE: 1.81263866964 -Train Accuracy: 0.933333\n",
      "epoch: 411 - cost: 0.189002 -MSE: 1.73989119492 -Train Accuracy: 0.933333\n",
      "epoch: 412 - cost: 0.187829 -MSE: 1.81547218957 -Train Accuracy: 0.939394\n",
      "epoch: 413 - cost: 0.188377 -MSE: 1.74306872774 -Train Accuracy: 0.933333\n",
      "epoch: 414 - cost: 0.187228 -MSE: 1.81832619828 -Train Accuracy: 0.939394\n",
      "epoch: 415 - cost: 0.187757 -MSE: 1.74626711074 -Train Accuracy: 0.933333\n",
      "epoch: 416 - cost: 0.18663 -MSE: 1.82120129654 -Train Accuracy: 0.939394\n",
      "epoch: 417 - cost: 0.18714 -MSE: 1.74948711833 -Train Accuracy: 0.933333\n",
      "epoch: 418 - cost: 0.186035 -MSE: 1.82409769982 -Train Accuracy: 0.939394\n",
      "epoch: 419 - cost: 0.186527 -MSE: 1.75272816079 -Train Accuracy: 0.933333\n",
      "epoch: 420 - cost: 0.185444 -MSE: 1.82701428102 -Train Accuracy: 0.939394\n",
      "epoch: 421 - cost: 0.185918 -MSE: 1.75599069018 -Train Accuracy: 0.933333\n",
      "epoch: 422 - cost: 0.184857 -MSE: 1.82995271259 -Train Accuracy: 0.939394\n",
      "epoch: 423 - cost: 0.185313 -MSE: 1.75927480217 -Train Accuracy: 0.933333\n",
      "epoch: 424 - cost: 0.184273 -MSE: 1.83291227734 -Train Accuracy: 0.939394\n",
      "epoch: 425 - cost: 0.184712 -MSE: 1.76257958809 -Train Accuracy: 0.933333\n",
      "epoch: 426 - cost: 0.183692 -MSE: 1.83589318876 -Train Accuracy: 0.945455\n",
      "epoch: 427 - cost: 0.184115 -MSE: 1.76590619071 -Train Accuracy: 0.933333\n",
      "epoch: 428 - cost: 0.183114 -MSE: 1.83889585736 -Train Accuracy: 0.945455\n",
      "epoch: 429 - cost: 0.183522 -MSE: 1.76925330973 -Train Accuracy: 0.933333\n",
      "epoch: 430 - cost: 0.18254 -MSE: 1.84192010988 -Train Accuracy: 0.945455\n",
      "epoch: 431 - cost: 0.182932 -MSE: 1.77262141219 -Train Accuracy: 0.933333\n",
      "epoch: 432 - cost: 0.18197 -MSE: 1.84496655568 -Train Accuracy: 0.945455\n",
      "epoch: 433 - cost: 0.182346 -MSE: 1.77601100987 -Train Accuracy: 0.933333\n",
      "epoch: 434 - cost: 0.181403 -MSE: 1.84803519611 -Train Accuracy: 0.945455\n",
      "epoch: 435 - cost: 0.181765 -MSE: 1.77942156599 -Train Accuracy: 0.933333\n",
      "epoch: 436 - cost: 0.180839 -MSE: 1.85112566193 -Train Accuracy: 0.951515\n",
      "epoch: 437 - cost: 0.181187 -MSE: 1.78285238732 -Train Accuracy: 0.933333\n",
      "epoch: 438 - cost: 0.180278 -MSE: 1.85423789872 -Train Accuracy: 0.951515\n",
      "epoch: 439 - cost: 0.180612 -MSE: 1.78630404567 -Train Accuracy: 0.933333\n",
      "epoch: 440 - cost: 0.179721 -MSE: 1.85737205144 -Train Accuracy: 0.951515\n",
      "epoch: 441 - cost: 0.180042 -MSE: 1.78977685478 -Train Accuracy: 0.933333\n",
      "epoch: 442 - cost: 0.179168 -MSE: 1.86052927272 -Train Accuracy: 0.951515\n",
      "epoch: 443 - cost: 0.179475 -MSE: 1.79326968862 -Train Accuracy: 0.933333\n",
      "epoch: 444 - cost: 0.178617 -MSE: 1.86370859112 -Train Accuracy: 0.951515\n",
      "epoch: 445 - cost: 0.178912 -MSE: 1.79678307421 -Train Accuracy: 0.933333\n",
      "epoch: 446 - cost: 0.17807 -MSE: 1.86691041434 -Train Accuracy: 0.951515\n",
      "epoch: 447 - cost: 0.178353 -MSE: 1.80031702787 -Train Accuracy: 0.933333\n",
      "epoch: 448 - cost: 0.177527 -MSE: 1.87013524819 -Train Accuracy: 0.951515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 449 - cost: 0.177798 -MSE: 1.80387153883 -Train Accuracy: 0.933333\n",
      "epoch: 450 - cost: 0.176986 -MSE: 1.87338205561 -Train Accuracy: 0.951515\n",
      "epoch: 451 - cost: 0.177246 -MSE: 1.8074455431 -Train Accuracy: 0.933333\n",
      "epoch: 452 - cost: 0.176449 -MSE: 1.87665214252 -Train Accuracy: 0.951515\n",
      "epoch: 453 - cost: 0.176698 -MSE: 1.81104014353 -Train Accuracy: 0.933333\n",
      "epoch: 454 - cost: 0.175916 -MSE: 1.87994520711 -Train Accuracy: 0.951515\n",
      "epoch: 455 - cost: 0.176154 -MSE: 1.81465496524 -Train Accuracy: 0.933333\n",
      "epoch: 456 - cost: 0.175386 -MSE: 1.88326042357 -Train Accuracy: 0.951515\n",
      "epoch: 457 - cost: 0.175613 -MSE: 1.818288983 -Train Accuracy: 0.933333\n",
      "epoch: 458 - cost: 0.174858 -MSE: 1.88659901912 -Train Accuracy: 0.951515\n",
      "epoch: 459 - cost: 0.175076 -MSE: 1.82194267002 -Train Accuracy: 0.933333\n",
      "epoch: 460 - cost: 0.174335 -MSE: 1.88996039684 -Train Accuracy: 0.951515\n",
      "epoch: 461 - cost: 0.174542 -MSE: 1.82561649528 -Train Accuracy: 0.933333\n",
      "epoch: 462 - cost: 0.173814 -MSE: 1.893344722 -Train Accuracy: 0.951515\n",
      "epoch: 463 - cost: 0.174012 -MSE: 1.8293092651 -Train Accuracy: 0.933333\n",
      "epoch: 464 - cost: 0.173297 -MSE: 1.89675208798 -Train Accuracy: 0.951515\n",
      "epoch: 465 - cost: 0.173486 -MSE: 1.83302111497 -Train Accuracy: 0.933333\n",
      "epoch: 466 - cost: 0.172783 -MSE: 1.90018254284 -Train Accuracy: 0.951515\n",
      "epoch: 467 - cost: 0.172963 -MSE: 1.83675296931 -Train Accuracy: 0.933333\n",
      "epoch: 468 - cost: 0.172272 -MSE: 1.90363585021 -Train Accuracy: 0.951515\n",
      "epoch: 469 - cost: 0.172444 -MSE: 1.84050303896 -Train Accuracy: 0.933333\n",
      "epoch: 470 - cost: 0.171764 -MSE: 1.90711200203 -Train Accuracy: 0.951515\n",
      "epoch: 471 - cost: 0.171928 -MSE: 1.84427177008 -Train Accuracy: 0.933333\n",
      "epoch: 472 - cost: 0.171259 -MSE: 1.91061137825 -Train Accuracy: 0.951515\n",
      "epoch: 473 - cost: 0.171415 -MSE: 1.8480598711 -Train Accuracy: 0.933333\n",
      "epoch: 474 - cost: 0.170758 -MSE: 1.91413365491 -Train Accuracy: 0.951515\n",
      "epoch: 475 - cost: 0.170906 -MSE: 1.85186606685 -Train Accuracy: 0.933333\n",
      "epoch: 476 - cost: 0.17026 -MSE: 1.91767901412 -Train Accuracy: 0.951515\n",
      "epoch: 477 - cost: 0.1704 -MSE: 1.85569060448 -Train Accuracy: 0.933333\n",
      "epoch: 478 - cost: 0.169764 -MSE: 1.92124806835 -Train Accuracy: 0.951515\n",
      "epoch: 479 - cost: 0.169898 -MSE: 1.85953420519 -Train Accuracy: 0.933333\n",
      "epoch: 480 - cost: 0.169272 -MSE: 1.92483962328 -Train Accuracy: 0.957576\n",
      "epoch: 481 - cost: 0.169399 -MSE: 1.86339488105 -Train Accuracy: 0.939394\n",
      "epoch: 482 - cost: 0.168783 -MSE: 1.92845446247 -Train Accuracy: 0.957576\n",
      "epoch: 483 - cost: 0.168903 -MSE: 1.86727418574 -Train Accuracy: 0.939394\n",
      "epoch: 484 - cost: 0.168297 -MSE: 1.9320920122 -Train Accuracy: 0.957576\n",
      "epoch: 485 - cost: 0.168411 -MSE: 1.87117060303 -Train Accuracy: 0.945455\n",
      "epoch: 486 - cost: 0.167814 -MSE: 1.93575308345 -Train Accuracy: 0.957576\n",
      "epoch: 487 - cost: 0.167922 -MSE: 1.87508487798 -Train Accuracy: 0.945455\n",
      "epoch: 488 - cost: 0.167334 -MSE: 1.9394365736 -Train Accuracy: 0.957576\n",
      "epoch: 489 - cost: 0.167436 -MSE: 1.87901653992 -Train Accuracy: 0.945455\n",
      "epoch: 490 - cost: 0.166857 -MSE: 1.94314323703 -Train Accuracy: 0.957576\n",
      "epoch: 491 - cost: 0.166953 -MSE: 1.8829660325 -Train Accuracy: 0.945455\n",
      "epoch: 492 - cost: 0.166382 -MSE: 1.94687276396 -Train Accuracy: 0.957576\n",
      "epoch: 493 - cost: 0.166474 -MSE: 1.88693177194 -Train Accuracy: 0.945455\n",
      "epoch: 494 - cost: 0.165911 -MSE: 1.95062569206 -Train Accuracy: 0.957576\n",
      "epoch: 495 - cost: 0.165997 -MSE: 1.89091493376 -Train Accuracy: 0.945455\n",
      "epoch: 496 - cost: 0.165443 -MSE: 1.95440092648 -Train Accuracy: 0.957576\n",
      "epoch: 497 - cost: 0.165524 -MSE: 1.8949145321 -Train Accuracy: 0.945455\n",
      "epoch: 498 - cost: 0.164977 -MSE: 1.95819921065 -Train Accuracy: 0.957576\n",
      "epoch: 499 - cost: 0.165054 -MSE: 1.89893061233 -Train Accuracy: 0.945455\n",
      "epoch: 500 - cost: 0.164515 -MSE: 1.96202076702 -Train Accuracy: 0.957576\n",
      "epoch: 501 - cost: 0.164587 -MSE: 1.90296340815 -Train Accuracy: 0.945455\n",
      "epoch: 502 - cost: 0.164055 -MSE: 1.9658641564 -Train Accuracy: 0.957576\n",
      "epoch: 503 - cost: 0.164122 -MSE: 1.90701234922 -Train Accuracy: 0.945455\n",
      "epoch: 504 - cost: 0.163598 -MSE: 1.96973069074 -Train Accuracy: 0.957576\n",
      "epoch: 505 - cost: 0.163661 -MSE: 1.91107754229 -Train Accuracy: 0.945455\n",
      "epoch: 506 - cost: 0.163144 -MSE: 1.97362016477 -Train Accuracy: 0.957576\n",
      "epoch: 507 - cost: 0.163203 -MSE: 1.91515842269 -Train Accuracy: 0.945455\n",
      "epoch: 508 - cost: 0.162693 -MSE: 1.9775319455 -Train Accuracy: 0.957576\n",
      "epoch: 509 - cost: 0.162748 -MSE: 1.91925460505 -Train Accuracy: 0.945455\n",
      "epoch: 510 - cost: 0.162244 -MSE: 1.98146658281 -Train Accuracy: 0.957576\n",
      "epoch: 511 - cost: 0.162296 -MSE: 1.92336693145 -Train Accuracy: 0.945455\n",
      "epoch: 512 - cost: 0.161798 -MSE: 1.98542314929 -Train Accuracy: 0.957576\n",
      "epoch: 513 - cost: 0.161847 -MSE: 1.92749462888 -Train Accuracy: 0.945455\n",
      "epoch: 514 - cost: 0.161355 -MSE: 1.98940316406 -Train Accuracy: 0.957576\n",
      "epoch: 515 - cost: 0.1614 -MSE: 1.93163769998 -Train Accuracy: 0.945455\n",
      "epoch: 516 - cost: 0.160915 -MSE: 1.99340447383 -Train Accuracy: 0.957576\n",
      "epoch: 517 - cost: 0.160957 -MSE: 1.93579514743 -Train Accuracy: 0.945455\n",
      "epoch: 518 - cost: 0.160477 -MSE: 1.99742894779 -Train Accuracy: 0.957576\n",
      "epoch: 519 - cost: 0.160516 -MSE: 1.9399682452 -Train Accuracy: 0.945455\n",
      "epoch: 520 - cost: 0.160042 -MSE: 2.00147565971 -Train Accuracy: 0.957576\n",
      "epoch: 521 - cost: 0.160078 -MSE: 1.94415559278 -Train Accuracy: 0.945455\n",
      "epoch: 522 - cost: 0.15961 -MSE: 2.00554506219 -Train Accuracy: 0.957576\n",
      "epoch: 523 - cost: 0.159643 -MSE: 1.94835742842 -Train Accuracy: 0.945455\n",
      "epoch: 524 - cost: 0.15918 -MSE: 2.0096360659 -Train Accuracy: 0.957576\n",
      "epoch: 525 - cost: 0.159211 -MSE: 1.95257367577 -Train Accuracy: 0.945455\n",
      "epoch: 526 - cost: 0.158753 -MSE: 2.01374963797 -Train Accuracy: 0.957576\n",
      "epoch: 527 - cost: 0.158782 -MSE: 1.95680384126 -Train Accuracy: 0.945455\n",
      "epoch: 528 - cost: 0.158328 -MSE: 2.01788463234 -Train Accuracy: 0.957576\n",
      "epoch: 529 - cost: 0.158355 -MSE: 1.96104870815 -Train Accuracy: 0.945455\n",
      "epoch: 530 - cost: 0.157907 -MSE: 2.02204238962 -Train Accuracy: 0.957576\n",
      "epoch: 531 - cost: 0.157931 -MSE: 1.96530678877 -Train Accuracy: 0.945455\n",
      "epoch: 532 - cost: 0.157487 -MSE: 2.02622172802 -Train Accuracy: 0.957576\n",
      "epoch: 533 - cost: 0.15751 -MSE: 1.96957907163 -Train Accuracy: 0.945455\n",
      "epoch: 534 - cost: 0.15707 -MSE: 2.03042273966 -Train Accuracy: 0.957576\n",
      "epoch: 535 - cost: 0.157091 -MSE: 1.97386444887 -Train Accuracy: 0.945455\n",
      "epoch: 536 - cost: 0.156656 -MSE: 2.03464566305 -Train Accuracy: 0.957576\n",
      "epoch: 537 - cost: 0.156675 -MSE: 1.97816330038 -Train Accuracy: 0.945455\n",
      "epoch: 538 - cost: 0.156245 -MSE: 2.03889072391 -Train Accuracy: 0.957576\n",
      "epoch: 539 - cost: 0.156262 -MSE: 1.98247607687 -Train Accuracy: 0.945455\n",
      "epoch: 540 - cost: 0.155835 -MSE: 2.04315686948 -Train Accuracy: 0.957576\n",
      "epoch: 541 - cost: 0.155851 -MSE: 1.98680126082 -Train Accuracy: 0.945455\n",
      "epoch: 542 - cost: 0.155429 -MSE: 2.04744531051 -Train Accuracy: 0.957576\n",
      "epoch: 543 - cost: 0.155443 -MSE: 1.99113942286 -Train Accuracy: 0.945455\n",
      "epoch: 544 - cost: 0.155025 -MSE: 2.05175503181 -Train Accuracy: 0.957576\n",
      "epoch: 545 - cost: 0.155038 -MSE: 1.99549011385 -Train Accuracy: 0.945455\n",
      "epoch: 546 - cost: 0.154623 -MSE: 2.05608576309 -Train Accuracy: 0.957576\n",
      "epoch: 547 - cost: 0.154635 -MSE: 1.99985331379 -Train Accuracy: 0.945455\n",
      "epoch: 548 - cost: 0.154224 -MSE: 2.06043876647 -Train Accuracy: 0.957576\n",
      "epoch: 549 - cost: 0.154235 -MSE: 2.00422956333 -Train Accuracy: 0.945455\n",
      "epoch: 550 - cost: 0.153827 -MSE: 2.06481284539 -Train Accuracy: 0.957576\n",
      "epoch: 551 - cost: 0.153837 -MSE: 2.00861809212 -Train Accuracy: 0.945455\n",
      "epoch: 552 - cost: 0.153433 -MSE: 2.06920791962 -Train Accuracy: 0.957576\n",
      "epoch: 553 - cost: 0.153443 -MSE: 2.01301822808 -Train Accuracy: 0.945455\n",
      "epoch: 554 - cost: 0.153041 -MSE: 2.07362399264 -Train Accuracy: 0.957576\n",
      "epoch: 555 - cost: 0.15305 -MSE: 2.0174303992 -Train Accuracy: 0.945455\n",
      "epoch: 556 - cost: 0.152652 -MSE: 2.07806153867 -Train Accuracy: 0.957576\n",
      "epoch: 557 - cost: 0.15266 -MSE: 2.02185492776 -Train Accuracy: 0.945455\n",
      "epoch: 558 - cost: 0.152265 -MSE: 2.08251990113 -Train Accuracy: 0.957576\n",
      "epoch: 559 - cost: 0.152273 -MSE: 2.02629058162 -Train Accuracy: 0.945455\n",
      "epoch: 560 - cost: 0.15188 -MSE: 2.08699879131 -Train Accuracy: 0.963636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 561 - cost: 0.151888 -MSE: 2.03073817552 -Train Accuracy: 0.945455\n",
      "epoch: 562 - cost: 0.151498 -MSE: 2.09149917308 -Train Accuracy: 0.963636\n",
      "epoch: 563 - cost: 0.151506 -MSE: 2.03519716816 -Train Accuracy: 0.945455\n",
      "epoch: 564 - cost: 0.151118 -MSE: 2.09602015291 -Train Accuracy: 0.963636\n",
      "epoch: 565 - cost: 0.151126 -MSE: 2.03966734349 -Train Accuracy: 0.945455\n",
      "epoch: 566 - cost: 0.150741 -MSE: 2.10056255466 -Train Accuracy: 0.963636\n",
      "epoch: 567 - cost: 0.150749 -MSE: 2.04414862557 -Train Accuracy: 0.945455\n",
      "epoch: 568 - cost: 0.150366 -MSE: 2.10512511937 -Train Accuracy: 0.963636\n",
      "epoch: 569 - cost: 0.150374 -MSE: 2.04864153154 -Train Accuracy: 0.945455\n",
      "epoch: 570 - cost: 0.149994 -MSE: 2.10970761431 -Train Accuracy: 0.963636\n",
      "epoch: 571 - cost: 0.150002 -MSE: 2.05314464537 -Train Accuracy: 0.945455\n",
      "epoch: 572 - cost: 0.149624 -MSE: 2.11431156451 -Train Accuracy: 0.963636\n",
      "epoch: 573 - cost: 0.149632 -MSE: 2.05765903927 -Train Accuracy: 0.945455\n",
      "epoch: 574 - cost: 0.149256 -MSE: 2.11893512741 -Train Accuracy: 0.963636\n",
      "epoch: 575 - cost: 0.149265 -MSE: 2.06218343985 -Train Accuracy: 0.945455\n",
      "epoch: 576 - cost: 0.148891 -MSE: 2.1235793162 -Train Accuracy: 0.963636\n",
      "epoch: 577 - cost: 0.1489 -MSE: 2.06671924971 -Train Accuracy: 0.945455\n",
      "epoch: 578 - cost: 0.148528 -MSE: 2.12824411546 -Train Accuracy: 0.963636\n",
      "epoch: 579 - cost: 0.148538 -MSE: 2.07126456689 -Train Accuracy: 0.945455\n",
      "epoch: 580 - cost: 0.148168 -MSE: 2.13292818084 -Train Accuracy: 0.963636\n",
      "epoch: 581 - cost: 0.148178 -MSE: 2.07582082532 -Train Accuracy: 0.945455\n",
      "epoch: 582 - cost: 0.147809 -MSE: 2.13763291868 -Train Accuracy: 0.963636\n",
      "epoch: 583 - cost: 0.147821 -MSE: 2.0803863584 -Train Accuracy: 0.945455\n",
      "epoch: 584 - cost: 0.147454 -MSE: 2.14235688932 -Train Accuracy: 0.963636\n",
      "epoch: 585 - cost: 0.147466 -MSE: 2.08496265692 -Train Accuracy: 0.945455\n",
      "epoch: 586 - cost: 0.1471 -MSE: 2.14710088909 -Train Accuracy: 0.963636\n",
      "epoch: 587 - cost: 0.147113 -MSE: 2.08954870527 -Train Accuracy: 0.945455\n",
      "epoch: 588 - cost: 0.146749 -MSE: 2.15186437268 -Train Accuracy: 0.963636\n",
      "epoch: 589 - cost: 0.146763 -MSE: 2.09414452392 -Train Accuracy: 0.945455\n",
      "epoch: 590 - cost: 0.1464 -MSE: 2.1566475781 -Train Accuracy: 0.963636\n",
      "epoch: 591 - cost: 0.146415 -MSE: 2.0987501082 -Train Accuracy: 0.945455\n",
      "epoch: 592 - cost: 0.146054 -MSE: 2.16144957116 -Train Accuracy: 0.963636\n",
      "epoch: 593 - cost: 0.14607 -MSE: 2.1033656207 -Train Accuracy: 0.945455\n",
      "epoch: 594 - cost: 0.14571 -MSE: 2.16627144477 -Train Accuracy: 0.969697\n",
      "epoch: 595 - cost: 0.145727 -MSE: 2.10799035772 -Train Accuracy: 0.945455\n",
      "epoch: 596 - cost: 0.145368 -MSE: 2.17111267862 -Train Accuracy: 0.969697\n",
      "epoch: 597 - cost: 0.145387 -MSE: 2.11262466409 -Train Accuracy: 0.945455\n",
      "epoch: 598 - cost: 0.145029 -MSE: 2.17597239634 -Train Accuracy: 0.969697\n",
      "epoch: 599 - cost: 0.145049 -MSE: 2.11726798677 -Train Accuracy: 0.945455\n",
      "epoch: 600 - cost: 0.144691 -MSE: 2.18085067776 -Train Accuracy: 0.969697\n",
      "epoch: 601 - cost: 0.144713 -MSE: 2.12192040191 -Train Accuracy: 0.945455\n",
      "epoch: 602 - cost: 0.144357 -MSE: 2.18574735214 -Train Accuracy: 0.969697\n",
      "epoch: 603 - cost: 0.14438 -MSE: 2.1265813509 -Train Accuracy: 0.945455\n",
      "epoch: 604 - cost: 0.144024 -MSE: 2.19066303692 -Train Accuracy: 0.969697\n",
      "epoch: 605 - cost: 0.144049 -MSE: 2.13125220133 -Train Accuracy: 0.945455\n",
      "epoch: 606 - cost: 0.143694 -MSE: 2.19559641854 -Train Accuracy: 0.969697\n",
      "epoch: 607 - cost: 0.143721 -MSE: 2.13593186529 -Train Accuracy: 0.945455\n",
      "epoch: 608 - cost: 0.143366 -MSE: 2.20054700167 -Train Accuracy: 0.969697\n",
      "epoch: 609 - cost: 0.143394 -MSE: 2.14061948487 -Train Accuracy: 0.945455\n",
      "epoch: 610 - cost: 0.14304 -MSE: 2.20551653345 -Train Accuracy: 0.969697\n",
      "epoch: 611 - cost: 0.14307 -MSE: 2.14531631524 -Train Accuracy: 0.945455\n",
      "epoch: 612 - cost: 0.142716 -MSE: 2.21050367298 -Train Accuracy: 0.969697\n",
      "epoch: 613 - cost: 0.142749 -MSE: 2.15002149469 -Train Accuracy: 0.945455\n",
      "epoch: 614 - cost: 0.142395 -MSE: 2.21550691857 -Train Accuracy: 0.969697\n",
      "epoch: 615 - cost: 0.142429 -MSE: 2.15473547138 -Train Accuracy: 0.945455\n",
      "epoch: 616 - cost: 0.142075 -MSE: 2.22052717425 -Train Accuracy: 0.969697\n",
      "epoch: 617 - cost: 0.142112 -MSE: 2.1594570854 -Train Accuracy: 0.945455\n",
      "epoch: 618 - cost: 0.141758 -MSE: 2.22556413098 -Train Accuracy: 0.969697\n",
      "epoch: 619 - cost: 0.141797 -MSE: 2.16418691902 -Train Accuracy: 0.945455\n",
      "epoch: 620 - cost: 0.141443 -MSE: 2.23061669576 -Train Accuracy: 0.969697\n",
      "epoch: 621 - cost: 0.141484 -MSE: 2.16892479348 -Train Accuracy: 0.945455\n",
      "epoch: 622 - cost: 0.141129 -MSE: 2.2356848279 -Train Accuracy: 0.969697\n",
      "epoch: 623 - cost: 0.141172 -MSE: 2.1736701735 -Train Accuracy: 0.945455\n",
      "epoch: 624 - cost: 0.140818 -MSE: 2.2407679519 -Train Accuracy: 0.969697\n",
      "epoch: 625 - cost: 0.140863 -MSE: 2.1784231417 -Train Accuracy: 0.945455\n",
      "epoch: 626 - cost: 0.140509 -MSE: 2.24586595117 -Train Accuracy: 0.969697\n",
      "epoch: 627 - cost: 0.140556 -MSE: 2.18318353042 -Train Accuracy: 0.945455\n",
      "epoch: 628 - cost: 0.140201 -MSE: 2.25097812205 -Train Accuracy: 0.969697\n",
      "epoch: 629 - cost: 0.140251 -MSE: 2.18795188452 -Train Accuracy: 0.945455\n",
      "epoch: 630 - cost: 0.139895 -MSE: 2.25610397533 -Train Accuracy: 0.969697\n",
      "epoch: 631 - cost: 0.139948 -MSE: 2.19272679334 -Train Accuracy: 0.945455\n",
      "epoch: 632 - cost: 0.139591 -MSE: 2.26124247975 -Train Accuracy: 0.969697\n",
      "epoch: 633 - cost: 0.139646 -MSE: 2.19750862779 -Train Accuracy: 0.945455\n",
      "epoch: 634 - cost: 0.139289 -MSE: 2.26639324483 -Train Accuracy: 0.969697\n",
      "epoch: 635 - cost: 0.139346 -MSE: 2.20229701303 -Train Accuracy: 0.945455\n",
      "epoch: 636 - cost: 0.138988 -MSE: 2.27155538618 -Train Accuracy: 0.969697\n",
      "epoch: 637 - cost: 0.139047 -MSE: 2.20709146675 -Train Accuracy: 0.945455\n",
      "epoch: 638 - cost: 0.138688 -MSE: 2.27672906129 -Train Accuracy: 0.969697\n",
      "epoch: 639 - cost: 0.13875 -MSE: 2.2118926699 -Train Accuracy: 0.945455\n",
      "epoch: 640 - cost: 0.13839 -MSE: 2.2819119905 -Train Accuracy: 0.969697\n",
      "epoch: 641 - cost: 0.138454 -MSE: 2.21669903149 -Train Accuracy: 0.945455\n",
      "epoch: 642 - cost: 0.138093 -MSE: 2.28710352921 -Train Accuracy: 0.969697\n",
      "epoch: 643 - cost: 0.138159 -MSE: 2.22151109873 -Train Accuracy: 0.945455\n",
      "epoch: 644 - cost: 0.137797 -MSE: 2.29230285995 -Train Accuracy: 0.969697\n",
      "epoch: 645 - cost: 0.137865 -MSE: 2.22632836926 -Train Accuracy: 0.945455\n",
      "epoch: 646 - cost: 0.137502 -MSE: 2.29750884679 -Train Accuracy: 0.969697\n",
      "epoch: 647 - cost: 0.137572 -MSE: 2.231150362 -Train Accuracy: 0.945455\n",
      "epoch: 648 - cost: 0.137207 -MSE: 2.30272005774 -Train Accuracy: 0.969697\n",
      "epoch: 649 - cost: 0.13728 -MSE: 2.23597596603 -Train Accuracy: 0.945455\n",
      "epoch: 650 - cost: 0.136914 -MSE: 2.30793481746 -Train Accuracy: 0.969697\n",
      "epoch: 651 - cost: 0.136988 -MSE: 2.24080633834 -Train Accuracy: 0.945455\n",
      "epoch: 652 - cost: 0.13662 -MSE: 2.31315274055 -Train Accuracy: 0.975758\n",
      "epoch: 653 - cost: 0.136696 -MSE: 2.24563918308 -Train Accuracy: 0.945455\n",
      "epoch: 654 - cost: 0.136326 -MSE: 2.31837191944 -Train Accuracy: 0.975758\n",
      "epoch: 655 - cost: 0.136404 -MSE: 2.25047541897 -Train Accuracy: 0.945455\n",
      "epoch: 656 - cost: 0.136033 -MSE: 2.32359073954 -Train Accuracy: 0.975758\n",
      "epoch: 657 - cost: 0.136112 -MSE: 2.25531360546 -Train Accuracy: 0.945455\n",
      "epoch: 658 - cost: 0.135739 -MSE: 2.32880674298 -Train Accuracy: 0.975758\n",
      "epoch: 659 - cost: 0.13582 -MSE: 2.26015383018 -Train Accuracy: 0.945455\n",
      "epoch: 660 - cost: 0.135445 -MSE: 2.33401865391 -Train Accuracy: 0.975758\n",
      "epoch: 661 - cost: 0.135526 -MSE: 2.26499464098 -Train Accuracy: 0.945455\n",
      "epoch: 662 - cost: 0.135149 -MSE: 2.33922445934 -Train Accuracy: 0.981818\n",
      "epoch: 663 - cost: 0.135232 -MSE: 2.26983612562 -Train Accuracy: 0.945455\n",
      "epoch: 664 - cost: 0.134852 -MSE: 2.34442175067 -Train Accuracy: 0.981818\n",
      "epoch: 665 - cost: 0.134935 -MSE: 2.27467739858 -Train Accuracy: 0.945455\n",
      "epoch: 666 - cost: 0.134554 -MSE: 2.34960740042 -Train Accuracy: 0.981818\n",
      "epoch: 667 - cost: 0.134637 -MSE: 2.27951691541 -Train Accuracy: 0.945455\n",
      "epoch: 668 - cost: 0.134254 -MSE: 2.35477963963 -Train Accuracy: 0.981818\n",
      "epoch: 669 - cost: 0.134337 -MSE: 2.28435381454 -Train Accuracy: 0.945455\n",
      "epoch: 670 - cost: 0.133951 -MSE: 2.35993592572 -Train Accuracy: 0.981818\n",
      "epoch: 671 - cost: 0.134034 -MSE: 2.28918753849 -Train Accuracy: 0.945455\n",
      "epoch: 672 - cost: 0.133646 -MSE: 2.36507263594 -Train Accuracy: 0.981818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 673 - cost: 0.133728 -MSE: 2.29401838586 -Train Accuracy: 0.945455\n",
      "epoch: 674 - cost: 0.133337 -MSE: 2.37018844462 -Train Accuracy: 0.981818\n",
      "epoch: 675 - cost: 0.133418 -MSE: 2.29884357217 -Train Accuracy: 0.945455\n",
      "epoch: 676 - cost: 0.133025 -MSE: 2.37527787376 -Train Accuracy: 0.981818\n",
      "epoch: 677 - cost: 0.133105 -MSE: 2.30366267427 -Train Accuracy: 0.945455\n",
      "epoch: 678 - cost: 0.132709 -MSE: 2.38033839392 -Train Accuracy: 0.981818\n",
      "epoch: 679 - cost: 0.132786 -MSE: 2.30847483249 -Train Accuracy: 0.945455\n",
      "epoch: 680 - cost: 0.132388 -MSE: 2.38536666974 -Train Accuracy: 0.981818\n",
      "epoch: 681 - cost: 0.132463 -MSE: 2.31327818103 -Train Accuracy: 0.945455\n",
      "epoch: 682 - cost: 0.132061 -MSE: 2.39035964702 -Train Accuracy: 0.981818\n",
      "epoch: 683 - cost: 0.132133 -MSE: 2.31807135583 -Train Accuracy: 0.945455\n",
      "epoch: 684 - cost: 0.13173 -MSE: 2.39531221444 -Train Accuracy: 0.981818\n",
      "epoch: 685 - cost: 0.131798 -MSE: 2.32285539669 -Train Accuracy: 0.945455\n",
      "epoch: 686 - cost: 0.131392 -MSE: 2.40022091131 -Train Accuracy: 0.981818\n",
      "epoch: 687 - cost: 0.131456 -MSE: 2.32762651887 -Train Accuracy: 0.945455\n",
      "epoch: 688 - cost: 0.131047 -MSE: 2.40508231874 -Train Accuracy: 0.981818\n",
      "epoch: 689 - cost: 0.131106 -MSE: 2.33238567496 -Train Accuracy: 0.945455\n",
      "epoch: 690 - cost: 0.130695 -MSE: 2.4098917132 -Train Accuracy: 0.981818\n",
      "epoch: 691 - cost: 0.130748 -MSE: 2.33713108202 -Train Accuracy: 0.945455\n",
      "epoch: 692 - cost: 0.130335 -MSE: 2.41464528648 -Train Accuracy: 0.981818\n",
      "epoch: 693 - cost: 0.130382 -MSE: 2.34186074394 -Train Accuracy: 0.945455\n",
      "epoch: 694 - cost: 0.129966 -MSE: 2.4193387159 -Train Accuracy: 0.981818\n",
      "epoch: 695 - cost: 0.130006 -MSE: 2.3465757595 -Train Accuracy: 0.945455\n",
      "epoch: 696 - cost: 0.129588 -MSE: 2.42396848517 -Train Accuracy: 0.981818\n",
      "epoch: 697 - cost: 0.129621 -MSE: 2.3512731055 -Train Accuracy: 0.945455\n",
      "epoch: 698 - cost: 0.129201 -MSE: 2.4285304938 -Train Accuracy: 0.981818\n",
      "epoch: 699 - cost: 0.129226 -MSE: 2.35595432449 -Train Accuracy: 0.945455\n",
      "epoch: 700 - cost: 0.128805 -MSE: 2.43302079274 -Train Accuracy: 0.981818\n",
      "epoch: 701 - cost: 0.12882 -MSE: 2.3606184563 -Train Accuracy: 0.945455\n",
      "epoch: 702 - cost: 0.128397 -MSE: 2.43743687133 -Train Accuracy: 0.981818\n",
      "epoch: 703 - cost: 0.128404 -MSE: 2.36526433497 -Train Accuracy: 0.945455\n",
      "epoch: 704 - cost: 0.12798 -MSE: 2.44177438566 -Train Accuracy: 0.981818\n",
      "epoch: 705 - cost: 0.127976 -MSE: 2.36989348718 -Train Accuracy: 0.945455\n",
      "epoch: 706 - cost: 0.127551 -MSE: 2.44603197002 -Train Accuracy: 0.981818\n",
      "epoch: 707 - cost: 0.127537 -MSE: 2.37450492473 -Train Accuracy: 0.945455\n",
      "epoch: 708 - cost: 0.127112 -MSE: 2.45020751027 -Train Accuracy: 0.981818\n",
      "epoch: 709 - cost: 0.127086 -MSE: 2.37910116776 -Train Accuracy: 0.945455\n",
      "epoch: 710 - cost: 0.126661 -MSE: 2.45429990277 -Train Accuracy: 0.981818\n",
      "epoch: 711 - cost: 0.126624 -MSE: 2.38368288553 -Train Accuracy: 0.945455\n",
      "epoch: 712 - cost: 0.126199 -MSE: 2.45830810185 -Train Accuracy: 0.981818\n",
      "epoch: 713 - cost: 0.126151 -MSE: 2.38825129817 -Train Accuracy: 0.945455\n",
      "epoch: 714 - cost: 0.125727 -MSE: 2.46223325488 -Train Accuracy: 0.981818\n",
      "epoch: 715 - cost: 0.125666 -MSE: 2.39280757599 -Train Accuracy: 0.945455\n",
      "epoch: 716 - cost: 0.125245 -MSE: 2.46607566786 -Train Accuracy: 0.981818\n",
      "epoch: 717 - cost: 0.125172 -MSE: 2.3973556696 -Train Accuracy: 0.945455\n",
      "epoch: 718 - cost: 0.124752 -MSE: 2.46983718365 -Train Accuracy: 0.981818\n",
      "epoch: 719 - cost: 0.124667 -MSE: 2.4018972679 -Train Accuracy: 0.945455\n",
      "epoch: 720 - cost: 0.124251 -MSE: 2.47352063996 -Train Accuracy: 0.981818\n",
      "epoch: 721 - cost: 0.124153 -MSE: 2.40643592877 -Train Accuracy: 0.951515\n",
      "epoch: 722 - cost: 0.123741 -MSE: 2.47713141173 -Train Accuracy: 0.981818\n",
      "epoch: 723 - cost: 0.123632 -MSE: 2.41097396455 -Train Accuracy: 0.951515\n",
      "epoch: 724 - cost: 0.123223 -MSE: 2.48067181748 -Train Accuracy: 0.981818\n",
      "epoch: 725 - cost: 0.123103 -MSE: 2.41551550031 -Train Accuracy: 0.951515\n",
      "epoch: 726 - cost: 0.122699 -MSE: 2.48414901742 -Train Accuracy: 0.981818\n",
      "epoch: 727 - cost: 0.122567 -MSE: 2.42006480626 -Train Accuracy: 0.957576\n",
      "epoch: 728 - cost: 0.122169 -MSE: 2.48757052541 -Train Accuracy: 0.981818\n",
      "epoch: 729 - cost: 0.122028 -MSE: 2.42462569116 -Train Accuracy: 0.957576\n",
      "epoch: 730 - cost: 0.121635 -MSE: 2.49094197865 -Train Accuracy: 0.981818\n",
      "epoch: 731 - cost: 0.121484 -MSE: 2.42920095806 -Train Accuracy: 0.957576\n",
      "epoch: 732 - cost: 0.121099 -MSE: 2.49427188193 -Train Accuracy: 0.981818\n",
      "epoch: 733 - cost: 0.120939 -MSE: 2.43379514907 -Train Accuracy: 0.957576\n",
      "epoch: 734 - cost: 0.12056 -MSE: 2.49756744525 -Train Accuracy: 0.981818\n",
      "epoch: 735 - cost: 0.120392 -MSE: 2.43841163944 -Train Accuracy: 0.957576\n",
      "epoch: 736 - cost: 0.120022 -MSE: 2.5008381021 -Train Accuracy: 0.981818\n",
      "epoch: 737 - cost: 0.119846 -MSE: 2.44305304415 -Train Accuracy: 0.957576\n",
      "epoch: 738 - cost: 0.119484 -MSE: 2.50409225179 -Train Accuracy: 0.981818\n",
      "epoch: 739 - cost: 0.119302 -MSE: 2.4477226315 -Train Accuracy: 0.957576\n",
      "epoch: 740 - cost: 0.118949 -MSE: 2.50733841678 -Train Accuracy: 0.981818\n",
      "epoch: 741 - cost: 0.118761 -MSE: 2.45242289046 -Train Accuracy: 0.963636\n",
      "epoch: 742 - cost: 0.118417 -MSE: 2.510584587 -Train Accuracy: 0.981818\n",
      "epoch: 743 - cost: 0.118225 -MSE: 2.45715519478 -Train Accuracy: 0.963636\n",
      "epoch: 744 - cost: 0.117889 -MSE: 2.51383865794 -Train Accuracy: 0.981818\n",
      "epoch: 745 - cost: 0.117694 -MSE: 2.4619215169 -Train Accuracy: 0.963636\n",
      "epoch: 746 - cost: 0.117367 -MSE: 2.51710833637 -Train Accuracy: 0.981818\n",
      "epoch: 747 - cost: 0.117169 -MSE: 2.46672295945 -Train Accuracy: 0.963636\n",
      "epoch: 748 - cost: 0.116852 -MSE: 2.52039993295 -Train Accuracy: 0.981818\n",
      "epoch: 749 - cost: 0.116651 -MSE: 2.47155927108 -Train Accuracy: 0.963636\n",
      "epoch: 750 - cost: 0.116343 -MSE: 2.52372030093 -Train Accuracy: 0.981818\n",
      "epoch: 751 - cost: 0.116141 -MSE: 2.47643076436 -Train Accuracy: 0.963636\n",
      "epoch: 752 - cost: 0.115842 -MSE: 2.52707425484 -Train Accuracy: 0.981818\n",
      "epoch: 753 - cost: 0.115639 -MSE: 2.48133657052 -Train Accuracy: 0.963636\n",
      "epoch: 754 - cost: 0.11535 -MSE: 2.53046613962 -Train Accuracy: 0.981818\n",
      "epoch: 755 - cost: 0.115146 -MSE: 2.48627595827 -Train Accuracy: 0.963636\n",
      "epoch: 756 - cost: 0.114865 -MSE: 2.53390093959 -Train Accuracy: 0.981818\n",
      "epoch: 757 - cost: 0.114662 -MSE: 2.49124720744 -Train Accuracy: 0.963636\n",
      "epoch: 758 - cost: 0.11439 -MSE: 2.53737980543 -Train Accuracy: 0.981818\n",
      "epoch: 759 - cost: 0.114188 -MSE: 2.49624936076 -Train Accuracy: 0.963636\n",
      "epoch: 760 - cost: 0.113924 -MSE: 2.54090793643 -Train Accuracy: 0.981818\n",
      "epoch: 761 - cost: 0.113723 -MSE: 2.50128015779 -Train Accuracy: 0.963636\n",
      "epoch: 762 - cost: 0.113467 -MSE: 2.54448539787 -Train Accuracy: 0.981818\n",
      "epoch: 763 - cost: 0.113267 -MSE: 2.50633803364 -Train Accuracy: 0.963636\n",
      "epoch: 764 - cost: 0.113018 -MSE: 2.54811280845 -Train Accuracy: 0.981818\n",
      "epoch: 765 - cost: 0.11282 -MSE: 2.51142002718 -Train Accuracy: 0.963636\n",
      "epoch: 766 - cost: 0.112579 -MSE: 2.5517921785 -Train Accuracy: 0.981818\n",
      "epoch: 767 - cost: 0.112382 -MSE: 2.51652472845 -Train Accuracy: 0.963636\n",
      "epoch: 768 - cost: 0.112148 -MSE: 2.5555220315 -Train Accuracy: 0.981818\n",
      "epoch: 769 - cost: 0.111953 -MSE: 2.52164998079 -Train Accuracy: 0.963636\n",
      "epoch: 770 - cost: 0.111725 -MSE: 2.55930387664 -Train Accuracy: 0.981818\n",
      "epoch: 771 - cost: 0.111532 -MSE: 2.52679247428 -Train Accuracy: 0.969697\n",
      "epoch: 772 - cost: 0.111311 -MSE: 2.56313513228 -Train Accuracy: 0.981818\n",
      "epoch: 773 - cost: 0.11112 -MSE: 2.53195176853 -Train Accuracy: 0.969697\n",
      "epoch: 774 - cost: 0.110904 -MSE: 2.56701627384 -Train Accuracy: 0.981818\n",
      "epoch: 775 - cost: 0.110716 -MSE: 2.53712429064 -Train Accuracy: 0.969697\n",
      "epoch: 776 - cost: 0.110505 -MSE: 2.57094527849 -Train Accuracy: 0.981818\n",
      "epoch: 777 - cost: 0.110319 -MSE: 2.54230918535 -Train Accuracy: 0.975758\n",
      "epoch: 778 - cost: 0.110113 -MSE: 2.57492080502 -Train Accuracy: 0.981818\n",
      "epoch: 779 - cost: 0.109929 -MSE: 2.54750462894 -Train Accuracy: 0.975758\n",
      "epoch: 780 - cost: 0.109727 -MSE: 2.57894209952 -Train Accuracy: 0.981818\n",
      "epoch: 781 - cost: 0.109546 -MSE: 2.55270706124 -Train Accuracy: 0.975758\n",
      "epoch: 782 - cost: 0.109349 -MSE: 2.58300667821 -Train Accuracy: 0.981818\n",
      "epoch: 783 - cost: 0.109169 -MSE: 2.5579173471 -Train Accuracy: 0.975758\n",
      "epoch: 784 - cost: 0.108976 -MSE: 2.58711311544 -Train Accuracy: 0.981818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 785 - cost: 0.108798 -MSE: 2.56313280942 -Train Accuracy: 0.975758\n",
      "epoch: 786 - cost: 0.108609 -MSE: 2.59126006643 -Train Accuracy: 0.981818\n",
      "epoch: 787 - cost: 0.108433 -MSE: 2.56835166178 -Train Accuracy: 0.975758\n",
      "epoch: 788 - cost: 0.108248 -MSE: 2.59544510772 -Train Accuracy: 0.981818\n",
      "epoch: 789 - cost: 0.108074 -MSE: 2.57357384754 -Train Accuracy: 0.975758\n",
      "epoch: 790 - cost: 0.107891 -MSE: 2.59966688528 -Train Accuracy: 0.981818\n",
      "epoch: 791 - cost: 0.107719 -MSE: 2.57879735728 -Train Accuracy: 0.981818\n",
      "epoch: 792 - cost: 0.10754 -MSE: 2.60392326176 -Train Accuracy: 0.981818\n",
      "epoch: 793 - cost: 0.107369 -MSE: 2.58402191514 -Train Accuracy: 0.981818\n",
      "epoch: 794 - cost: 0.107193 -MSE: 2.6082139524 -Train Accuracy: 0.981818\n",
      "epoch: 795 - cost: 0.107024 -MSE: 2.58924624566 -Train Accuracy: 0.981818\n",
      "epoch: 796 - cost: 0.10685 -MSE: 2.61253614916 -Train Accuracy: 0.981818\n",
      "epoch: 797 - cost: 0.106683 -MSE: 2.59446981499 -Train Accuracy: 0.981818\n",
      "epoch: 798 - cost: 0.106511 -MSE: 2.6168883428 -Train Accuracy: 0.981818\n",
      "epoch: 799 - cost: 0.106346 -MSE: 2.59969192361 -Train Accuracy: 0.981818\n",
      "epoch: 800 - cost: 0.106176 -MSE: 2.62126969038 -Train Accuracy: 0.981818\n",
      "epoch: 801 - cost: 0.106013 -MSE: 2.60491154528 -Train Accuracy: 0.981818\n",
      "epoch: 802 - cost: 0.105845 -MSE: 2.62567794611 -Train Accuracy: 0.981818\n",
      "epoch: 803 - cost: 0.105683 -MSE: 2.61012926005 -Train Accuracy: 0.981818\n",
      "epoch: 804 - cost: 0.105517 -MSE: 2.63011253168 -Train Accuracy: 0.981818\n",
      "epoch: 805 - cost: 0.105356 -MSE: 2.6153429532 -Train Accuracy: 0.981818\n",
      "epoch: 806 - cost: 0.105192 -MSE: 2.63457174672 -Train Accuracy: 0.981818\n",
      "epoch: 807 - cost: 0.105032 -MSE: 2.62055358821 -Train Accuracy: 0.981818\n",
      "epoch: 808 - cost: 0.10487 -MSE: 2.6390543566 -Train Accuracy: 0.981818\n",
      "epoch: 809 - cost: 0.104711 -MSE: 2.62576043247 -Train Accuracy: 0.981818\n",
      "epoch: 810 - cost: 0.104551 -MSE: 2.64355956375 -Train Accuracy: 0.981818\n",
      "epoch: 811 - cost: 0.104393 -MSE: 2.63096323796 -Train Accuracy: 0.981818\n",
      "epoch: 812 - cost: 0.104234 -MSE: 2.64808628571 -Train Accuracy: 0.981818\n",
      "epoch: 813 - cost: 0.104078 -MSE: 2.63616208607 -Train Accuracy: 0.981818\n",
      "epoch: 814 - cost: 0.10392 -MSE: 2.65263222657 -Train Accuracy: 0.981818\n",
      "epoch: 815 - cost: 0.103765 -MSE: 2.64135577548 -Train Accuracy: 0.981818\n",
      "epoch: 816 - cost: 0.103608 -MSE: 2.6571984593 -Train Accuracy: 0.981818\n",
      "epoch: 817 - cost: 0.103454 -MSE: 2.64654547879 -Train Accuracy: 0.981818\n",
      "epoch: 818 - cost: 0.103299 -MSE: 2.66178221871 -Train Accuracy: 0.981818\n",
      "epoch: 819 - cost: 0.103145 -MSE: 2.65172963158 -Train Accuracy: 0.981818\n",
      "epoch: 820 - cost: 0.102991 -MSE: 2.66638395254 -Train Accuracy: 0.981818\n",
      "epoch: 821 - cost: 0.102839 -MSE: 2.65690972349 -Train Accuracy: 0.981818\n",
      "epoch: 822 - cost: 0.102685 -MSE: 2.67100228876 -Train Accuracy: 0.981818\n",
      "epoch: 823 - cost: 0.102534 -MSE: 2.66208523705 -Train Accuracy: 0.981818\n",
      "epoch: 824 - cost: 0.102382 -MSE: 2.6756366209 -Train Accuracy: 0.981818\n",
      "epoch: 825 - cost: 0.102231 -MSE: 2.66725567498 -Train Accuracy: 0.981818\n",
      "epoch: 826 - cost: 0.10208 -MSE: 2.68028616401 -Train Accuracy: 0.981818\n",
      "epoch: 827 - cost: 0.10193 -MSE: 2.6724203124 -Train Accuracy: 0.981818\n",
      "epoch: 828 - cost: 0.101779 -MSE: 2.68495103589 -Train Accuracy: 0.981818\n",
      "epoch: 829 - cost: 0.10163 -MSE: 2.677580692 -Train Accuracy: 0.981818\n",
      "epoch: 830 - cost: 0.101481 -MSE: 2.68962888462 -Train Accuracy: 0.981818\n",
      "epoch: 831 - cost: 0.101332 -MSE: 2.68273588458 -Train Accuracy: 0.981818\n",
      "epoch: 832 - cost: 0.101184 -MSE: 2.69432045203 -Train Accuracy: 0.981818\n",
      "epoch: 833 - cost: 0.101036 -MSE: 2.68788569822 -Train Accuracy: 0.981818\n",
      "epoch: 834 - cost: 0.100888 -MSE: 2.69902410563 -Train Accuracy: 0.981818\n",
      "epoch: 835 - cost: 0.100741 -MSE: 2.69303042973 -Train Accuracy: 0.981818\n",
      "epoch: 836 - cost: 0.100593 -MSE: 2.70374077358 -Train Accuracy: 0.981818\n",
      "epoch: 837 - cost: 0.100447 -MSE: 2.69817118066 -Train Accuracy: 0.981818\n",
      "epoch: 838 - cost: 0.1003 -MSE: 2.70846910836 -Train Accuracy: 0.981818\n",
      "epoch: 839 - cost: 0.100155 -MSE: 2.70330630698 -Train Accuracy: 0.981818\n",
      "epoch: 840 - cost: 0.100009 -MSE: 2.71320824363 -Train Accuracy: 0.981818\n",
      "epoch: 841 - cost: 0.0998634 -MSE: 2.70843696015 -Train Accuracy: 0.981818\n",
      "epoch: 842 - cost: 0.0997182 -MSE: 2.71795804835 -Train Accuracy: 0.981818\n",
      "epoch: 843 - cost: 0.0995735 -MSE: 2.71356190147 -Train Accuracy: 0.981818\n",
      "epoch: 844 - cost: 0.0994289 -MSE: 2.72271825437 -Train Accuracy: 0.981818\n",
      "epoch: 845 - cost: 0.0992847 -MSE: 2.71868257729 -Train Accuracy: 0.981818\n",
      "epoch: 846 - cost: 0.0991407 -MSE: 2.72748845847 -Train Accuracy: 0.981818\n",
      "epoch: 847 - cost: 0.0989971 -MSE: 2.72379868332 -Train Accuracy: 0.981818\n",
      "epoch: 848 - cost: 0.0988536 -MSE: 2.73226785851 -Train Accuracy: 0.981818\n",
      "epoch: 849 - cost: 0.0987105 -MSE: 2.72890974931 -Train Accuracy: 0.981818\n",
      "epoch: 850 - cost: 0.0985676 -MSE: 2.7370567093 -Train Accuracy: 0.981818\n",
      "epoch: 851 - cost: 0.098425 -MSE: 2.73401606886 -Train Accuracy: 0.981818\n",
      "epoch: 852 - cost: 0.0982826 -MSE: 2.74185404445 -Train Accuracy: 0.981818\n",
      "epoch: 853 - cost: 0.0981405 -MSE: 2.73911844543 -Train Accuracy: 0.981818\n",
      "epoch: 854 - cost: 0.0979986 -MSE: 2.74666079892 -Train Accuracy: 0.981818\n",
      "epoch: 855 - cost: 0.0978569 -MSE: 2.74421543135 -Train Accuracy: 0.981818\n",
      "epoch: 856 - cost: 0.0977155 -MSE: 2.75147524376 -Train Accuracy: 0.981818\n",
      "epoch: 857 - cost: 0.0975744 -MSE: 2.74930889936 -Train Accuracy: 0.981818\n",
      "epoch: 858 - cost: 0.0974334 -MSE: 2.75629743558 -Train Accuracy: 0.981818\n",
      "epoch: 859 - cost: 0.0972927 -MSE: 2.75439740738 -Train Accuracy: 0.981818\n",
      "epoch: 860 - cost: 0.0971522 -MSE: 2.76112750711 -Train Accuracy: 0.981818\n",
      "epoch: 861 - cost: 0.097012 -MSE: 2.7594821973 -Train Accuracy: 0.981818\n",
      "epoch: 862 - cost: 0.0968719 -MSE: 2.76596484484 -Train Accuracy: 0.981818\n",
      "epoch: 863 - cost: 0.0967321 -MSE: 2.76456259945 -Train Accuracy: 0.981818\n",
      "epoch: 864 - cost: 0.0965924 -MSE: 2.77080800473 -Train Accuracy: 0.981818\n",
      "epoch: 865 - cost: 0.0964531 -MSE: 2.7696385234 -Train Accuracy: 0.981818\n",
      "epoch: 866 - cost: 0.0963139 -MSE: 2.77565938155 -Train Accuracy: 0.981818\n",
      "epoch: 867 - cost: 0.0961749 -MSE: 2.77471030547 -Train Accuracy: 0.981818\n",
      "epoch: 868 - cost: 0.0960361 -MSE: 2.78051731804 -Train Accuracy: 0.981818\n",
      "epoch: 869 - cost: 0.0958975 -MSE: 2.77977883135 -Train Accuracy: 0.981818\n",
      "epoch: 870 - cost: 0.0957591 -MSE: 2.78538061638 -Train Accuracy: 0.981818\n",
      "epoch: 871 - cost: 0.095621 -MSE: 2.78484287949 -Train Accuracy: 0.981818\n",
      "epoch: 872 - cost: 0.095483 -MSE: 2.79025032641 -Train Accuracy: 0.981818\n",
      "epoch: 873 - cost: 0.0953452 -MSE: 2.78990314515 -Train Accuracy: 0.981818\n",
      "epoch: 874 - cost: 0.0952076 -MSE: 2.79512543214 -Train Accuracy: 0.981818\n",
      "epoch: 875 - cost: 0.0950702 -MSE: 2.7949603776 -Train Accuracy: 0.981818\n",
      "epoch: 876 - cost: 0.094933 -MSE: 2.80000643161 -Train Accuracy: 0.981818\n",
      "epoch: 877 - cost: 0.094796 -MSE: 2.80001389175 -Train Accuracy: 0.981818\n",
      "epoch: 878 - cost: 0.0946592 -MSE: 2.8048925711 -Train Accuracy: 0.981818\n",
      "epoch: 879 - cost: 0.0945226 -MSE: 2.80506393186 -Train Accuracy: 0.981818\n",
      "epoch: 880 - cost: 0.0943861 -MSE: 2.80978395761 -Train Accuracy: 0.981818\n",
      "epoch: 881 - cost: 0.0942498 -MSE: 2.81011006042 -Train Accuracy: 0.987879\n",
      "epoch: 882 - cost: 0.0941138 -MSE: 2.8146803566 -Train Accuracy: 0.981818\n",
      "epoch: 883 - cost: 0.0939779 -MSE: 2.8151536742 -Train Accuracy: 0.987879\n",
      "epoch: 884 - cost: 0.0938422 -MSE: 2.81958143822 -Train Accuracy: 0.981818\n",
      "epoch: 885 - cost: 0.0937066 -MSE: 2.82019347816 -Train Accuracy: 0.987879\n",
      "epoch: 886 - cost: 0.0935713 -MSE: 2.82448719051 -Train Accuracy: 0.987879\n",
      "epoch: 887 - cost: 0.0934361 -MSE: 2.8252308487 -Train Accuracy: 0.987879\n",
      "epoch: 888 - cost: 0.0933011 -MSE: 2.82939774526 -Train Accuracy: 0.987879\n",
      "epoch: 889 - cost: 0.0931663 -MSE: 2.83026483667 -Train Accuracy: 0.987879\n",
      "epoch: 890 - cost: 0.0930316 -MSE: 2.83431196062 -Train Accuracy: 0.987879\n",
      "epoch: 891 - cost: 0.0928972 -MSE: 2.83529600453 -Train Accuracy: 0.987879\n",
      "epoch: 892 - cost: 0.0927629 -MSE: 2.83922984003 -Train Accuracy: 0.987879\n",
      "epoch: 893 - cost: 0.0926287 -MSE: 2.84032395774 -Train Accuracy: 0.987879\n",
      "epoch: 894 - cost: 0.0924948 -MSE: 2.84415232903 -Train Accuracy: 0.987879\n",
      "epoch: 895 - cost: 0.092361 -MSE: 2.84534940066 -Train Accuracy: 0.987879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 896 - cost: 0.0922274 -MSE: 2.84907776501 -Train Accuracy: 0.987879\n",
      "epoch: 897 - cost: 0.092094 -MSE: 2.85037330097 -Train Accuracy: 0.987879\n",
      "epoch: 898 - cost: 0.0919608 -MSE: 2.85400727736 -Train Accuracy: 0.987879\n",
      "epoch: 899 - cost: 0.0918277 -MSE: 2.8553937022 -Train Accuracy: 0.987879\n",
      "epoch: 900 - cost: 0.0916947 -MSE: 2.85893998938 -Train Accuracy: 0.987879\n",
      "epoch: 901 - cost: 0.091562 -MSE: 2.86041127546 -Train Accuracy: 0.987879\n",
      "epoch: 902 - cost: 0.0914294 -MSE: 2.86387546363 -Train Accuracy: 0.987879\n",
      "epoch: 903 - cost: 0.091297 -MSE: 2.86542733918 -Train Accuracy: 0.987879\n",
      "epoch: 904 - cost: 0.0911648 -MSE: 2.86881432569 -Train Accuracy: 0.987879\n",
      "epoch: 905 - cost: 0.0910327 -MSE: 2.87044157247 -Train Accuracy: 0.987879\n",
      "epoch: 906 - cost: 0.0909008 -MSE: 2.873755332 -Train Accuracy: 0.987879\n",
      "epoch: 907 - cost: 0.0907691 -MSE: 2.8754532234 -Train Accuracy: 0.987879\n",
      "epoch: 908 - cost: 0.0906375 -MSE: 2.8786998768 -Train Accuracy: 0.987879\n",
      "epoch: 909 - cost: 0.0905061 -MSE: 2.88046301254 -Train Accuracy: 0.987879\n",
      "epoch: 910 - cost: 0.0903749 -MSE: 2.8836471429 -Train Accuracy: 0.987879\n",
      "epoch: 911 - cost: 0.0902438 -MSE: 2.88547047019 -Train Accuracy: 0.987879\n",
      "epoch: 912 - cost: 0.090113 -MSE: 2.88859577062 -Train Accuracy: 0.987879\n",
      "epoch: 913 - cost: 0.0899823 -MSE: 2.89047622 -Train Accuracy: 0.987879\n",
      "epoch: 914 - cost: 0.0898517 -MSE: 2.89354723667 -Train Accuracy: 0.987879\n",
      "epoch: 915 - cost: 0.0897213 -MSE: 2.89548048644 -Train Accuracy: 0.987879\n",
      "epoch: 916 - cost: 0.0895911 -MSE: 2.89850152963 -Train Accuracy: 0.987879\n",
      "epoch: 917 - cost: 0.089461 -MSE: 2.90048333628 -Train Accuracy: 0.987879\n",
      "epoch: 918 - cost: 0.0893311 -MSE: 2.90345717915 -Train Accuracy: 0.987879\n",
      "epoch: 919 - cost: 0.0892014 -MSE: 2.90548431184 -Train Accuracy: 0.987879\n",
      "epoch: 920 - cost: 0.0890718 -MSE: 2.90841502299 -Train Accuracy: 0.987879\n",
      "epoch: 921 - cost: 0.0889424 -MSE: 2.91048337713 -Train Accuracy: 0.987879\n",
      "epoch: 922 - cost: 0.0888132 -MSE: 2.91337480416 -Train Accuracy: 0.987879\n",
      "epoch: 923 - cost: 0.0886841 -MSE: 2.9154819772 -Train Accuracy: 0.987879\n",
      "epoch: 924 - cost: 0.0885552 -MSE: 2.91833580415 -Train Accuracy: 0.987879\n",
      "epoch: 925 - cost: 0.0884265 -MSE: 2.92047851552 -Train Accuracy: 0.987879\n",
      "epoch: 926 - cost: 0.0882979 -MSE: 2.92329831999 -Train Accuracy: 0.987879\n",
      "epoch: 927 - cost: 0.0881695 -MSE: 2.92547411586 -Train Accuracy: 0.987879\n",
      "epoch: 928 - cost: 0.0880413 -MSE: 2.92826210104 -Train Accuracy: 0.987879\n",
      "epoch: 929 - cost: 0.0879132 -MSE: 2.93046814022 -Train Accuracy: 0.987879\n",
      "epoch: 930 - cost: 0.0877853 -MSE: 2.93322728878 -Train Accuracy: 0.987879\n",
      "epoch: 931 - cost: 0.0876575 -MSE: 2.93546137857 -Train Accuracy: 0.987879\n",
      "epoch: 932 - cost: 0.0875299 -MSE: 2.93819479684 -Train Accuracy: 0.987879\n",
      "epoch: 933 - cost: 0.0874025 -MSE: 2.94045338844 -Train Accuracy: 0.987879\n",
      "epoch: 934 - cost: 0.0872753 -MSE: 2.94316223426 -Train Accuracy: 0.987879\n",
      "epoch: 935 - cost: 0.0871482 -MSE: 2.94544442744 -Train Accuracy: 0.987879\n",
      "epoch: 936 - cost: 0.0870213 -MSE: 2.94813152144 -Train Accuracy: 0.987879\n",
      "epoch: 937 - cost: 0.0868945 -MSE: 2.95043447128 -Train Accuracy: 0.987879\n",
      "epoch: 938 - cost: 0.0867679 -MSE: 2.95310078609 -Train Accuracy: 0.987879\n",
      "epoch: 939 - cost: 0.0866415 -MSE: 2.95542377853 -Train Accuracy: 0.987879\n",
      "epoch: 940 - cost: 0.0865152 -MSE: 2.95807152195 -Train Accuracy: 0.987879\n",
      "epoch: 941 - cost: 0.0863891 -MSE: 2.96041185726 -Train Accuracy: 0.987879\n",
      "epoch: 942 - cost: 0.0862632 -MSE: 2.96304341585 -Train Accuracy: 0.987879\n",
      "epoch: 943 - cost: 0.0861374 -MSE: 2.96539891694 -Train Accuracy: 0.987879\n",
      "epoch: 944 - cost: 0.0860118 -MSE: 2.9680159181 -Train Accuracy: 0.987879\n",
      "epoch: 945 - cost: 0.0858864 -MSE: 2.97038602742 -Train Accuracy: 0.987879\n",
      "epoch: 946 - cost: 0.0857611 -MSE: 2.97298841811 -Train Accuracy: 0.987879\n",
      "epoch: 947 - cost: 0.085636 -MSE: 2.97537174967 -Train Accuracy: 0.987879\n",
      "epoch: 948 - cost: 0.085511 -MSE: 2.97796241949 -Train Accuracy: 0.987879\n",
      "epoch: 949 - cost: 0.0853862 -MSE: 2.98035741319 -Train Accuracy: 0.987879\n",
      "epoch: 950 - cost: 0.0852617 -MSE: 2.98293593495 -Train Accuracy: 0.987879\n",
      "epoch: 951 - cost: 0.0851372 -MSE: 2.98534195817 -Train Accuracy: 0.987879\n",
      "epoch: 952 - cost: 0.0850129 -MSE: 2.98791055723 -Train Accuracy: 0.987879\n",
      "epoch: 953 - cost: 0.0848888 -MSE: 2.99032553422 -Train Accuracy: 0.987879\n",
      "epoch: 954 - cost: 0.0847648 -MSE: 2.99288467866 -Train Accuracy: 0.987879\n",
      "epoch: 955 - cost: 0.084641 -MSE: 2.99530937579 -Train Accuracy: 0.987879\n",
      "epoch: 956 - cost: 0.0845174 -MSE: 2.99786033329 -Train Accuracy: 0.987879\n",
      "epoch: 957 - cost: 0.0843939 -MSE: 3.00029164737 -Train Accuracy: 0.987879\n",
      "epoch: 958 - cost: 0.0842706 -MSE: 3.00283581762 -Train Accuracy: 0.987879\n",
      "epoch: 959 - cost: 0.0841475 -MSE: 3.00527388815 -Train Accuracy: 0.987879\n",
      "epoch: 960 - cost: 0.0840245 -MSE: 3.00781099981 -Train Accuracy: 0.987879\n",
      "epoch: 961 - cost: 0.0839017 -MSE: 3.01025551285 -Train Accuracy: 0.987879\n",
      "epoch: 962 - cost: 0.083779 -MSE: 3.0127865835 -Train Accuracy: 0.987879\n",
      "epoch: 963 - cost: 0.0836565 -MSE: 3.01523578842 -Train Accuracy: 0.987879\n",
      "epoch: 964 - cost: 0.0835342 -MSE: 3.01776229586 -Train Accuracy: 0.987879\n",
      "epoch: 965 - cost: 0.0834121 -MSE: 3.02021660861 -Train Accuracy: 0.987879\n",
      "epoch: 966 - cost: 0.0832901 -MSE: 3.02273778211 -Train Accuracy: 0.987879\n",
      "epoch: 967 - cost: 0.0831683 -MSE: 3.0251960554 -Train Accuracy: 0.987879\n",
      "epoch: 968 - cost: 0.0830466 -MSE: 3.02771384337 -Train Accuracy: 0.987879\n",
      "epoch: 969 - cost: 0.0829251 -MSE: 3.03017578616 -Train Accuracy: 0.987879\n",
      "epoch: 970 - cost: 0.0828038 -MSE: 3.0326892315 -Train Accuracy: 0.987879\n",
      "epoch: 971 - cost: 0.0826826 -MSE: 3.03515428 -Train Accuracy: 0.987879\n",
      "epoch: 972 - cost: 0.0825616 -MSE: 3.03766473612 -Train Accuracy: 0.987879\n",
      "epoch: 973 - cost: 0.0824408 -MSE: 3.04013290547 -Train Accuracy: 0.987879\n",
      "epoch: 974 - cost: 0.0823201 -MSE: 3.0426401511 -Train Accuracy: 0.987879\n",
      "epoch: 975 - cost: 0.0821996 -MSE: 3.04511092816 -Train Accuracy: 0.987879\n",
      "epoch: 976 - cost: 0.0820793 -MSE: 3.04761565137 -Train Accuracy: 0.987879\n",
      "epoch: 977 - cost: 0.0819591 -MSE: 3.05008828131 -Train Accuracy: 0.987879\n",
      "epoch: 978 - cost: 0.0818391 -MSE: 3.05258975194 -Train Accuracy: 0.987879\n",
      "epoch: 979 - cost: 0.0817192 -MSE: 3.05506519583 -Train Accuracy: 0.987879\n",
      "epoch: 980 - cost: 0.0815996 -MSE: 3.05756457916 -Train Accuracy: 0.987879\n",
      "epoch: 981 - cost: 0.08148 -MSE: 3.06004139978 -Train Accuracy: 0.987879\n",
      "epoch: 982 - cost: 0.0813607 -MSE: 3.06253941248 -Train Accuracy: 0.987879\n",
      "epoch: 983 - cost: 0.0812415 -MSE: 3.06501778794 -Train Accuracy: 0.987879\n",
      "epoch: 984 - cost: 0.0811225 -MSE: 3.06751355513 -Train Accuracy: 0.987879\n",
      "epoch: 985 - cost: 0.0810036 -MSE: 3.06999285181 -Train Accuracy: 0.987879\n",
      "epoch: 986 - cost: 0.0808849 -MSE: 3.07248727283 -Train Accuracy: 0.987879\n",
      "epoch: 987 - cost: 0.0807664 -MSE: 3.07496776895 -Train Accuracy: 0.987879\n",
      "epoch: 988 - cost: 0.080648 -MSE: 3.07746043765 -Train Accuracy: 0.987879\n",
      "epoch: 989 - cost: 0.0805298 -MSE: 3.07994115021 -Train Accuracy: 0.987879\n",
      "epoch: 990 - cost: 0.0804118 -MSE: 3.08243356176 -Train Accuracy: 0.987879\n",
      "epoch: 991 - cost: 0.0802939 -MSE: 3.08491528859 -Train Accuracy: 0.987879\n",
      "epoch: 992 - cost: 0.0801762 -MSE: 3.08740654577 -Train Accuracy: 0.987879\n",
      "epoch: 993 - cost: 0.0800586 -MSE: 3.08988850685 -Train Accuracy: 0.987879\n",
      "epoch: 994 - cost: 0.0799413 -MSE: 3.09237845767 -Train Accuracy: 0.987879\n",
      "epoch: 995 - cost: 0.0798241 -MSE: 3.09486115502 -Train Accuracy: 0.987879\n",
      "epoch: 996 - cost: 0.079707 -MSE: 3.0973500738 -Train Accuracy: 0.987879\n",
      "epoch: 997 - cost: 0.0795901 -MSE: 3.0998326887 -Train Accuracy: 0.987879\n",
      "epoch: 998 - cost: 0.0794734 -MSE: 3.10232154343 -Train Accuracy: 0.987879\n",
      "epoch: 999 - cost: 0.0793568 -MSE: 3.10480434201 -Train Accuracy: 0.987879\n",
      "Model saved in file: C:\\Users\\ayana\\Documents\\ML\\Machine Learning With Python\n"
     ]
    }
   ],
   "source": [
    "mse_history=[]\n",
    "accuracy_history=[]\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n",
    "    cost=sess.run(cost_function,feed_dict={x:train_x,y_:train_y})\n",
    "    cost_history=np.append(cost_history,cost)\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    #print accuracy\n",
    "    \n",
    "    pred_y=sess.run(y,feed_dict={x:test_x})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "    \n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=(sess.run(accuracy,feed_dict={x:train_x,y_:train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,\"-MSE:\",mse_,\"-Train Accuracy:\",accuracy)\n",
    "    \n",
    "save_path=saver.save(sess,model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv4hIyij4RURSRsEvIpIy/x+kAqvymlydfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0830bb390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mse and accuracy graph\n",
    "plt.plot(mse_history,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0831679e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.904762\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test Accuracy:\",(sess.run(accuracy,feed_dict={x:test_x,y_:test_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the final mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:3.1048\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(y,feed_dict={x:test_x})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "print(\"MSE:%.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=tf.argmax(y,1)\n",
    "correct_prediction=tf.equal(prediction,tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print accuracy run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "0 stands for M i.e. Mine and 1 stands for R i.e. Rock\n",
      "******************************\n",
      "93 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "94 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "95 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "96 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "97 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "98 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "99 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "100 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n"
     ]
    }
   ],
   "source": [
    "print('******************************')\n",
    "print(\"0 stands for M i.e. Mine and 1 stands for R i.e. Rock\")\n",
    "print('******************************')\n",
    "\n",
    "for i in range(93,101):\n",
    "    \n",
    "    prediction_run = sess.run(prediction, feed_dict={x:X[i].reshape(1,60)})\n",
    "    accuracy_run = sess.run(accuracy, feed_dict={x:X[i].reshape(1,60), y_:Y[i].reshape(1,2)})\n",
    "    print(i,\"Original Class: \", int(sess.run(y_[i][1],feed_dict={y_:Y})), \" Predicted Values: \", prediction_run[0] )\n",
    "    print(\"Accuracy: \",str(accuracy_run*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
